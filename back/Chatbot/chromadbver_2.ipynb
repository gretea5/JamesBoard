{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ea1908-7d46-4d3b-aef7-d4d9aa3dd27c",
   "metadata": {},
   "source": [
    "# 보드게임 추천 시스템 통합 파이프 라인\n",
    "이 노트북은 보드게임 리뷰와 메타데이터를 통합하여 벡터화하고 ChromaDB에 저장하는 전체 과정을 담고 있습니다. 한국어 쿼리로 영어 리뷰와 게임 데이터를 검색할 수 있는 크로스 언어 RAG 시스템 구축을 위한 파이프라인입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ae851-40be-46c8-a692-08cf2ff51f5c",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리 설치 및 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62188122-7380-4ea0-8dd4-d5be0ce1d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython==8.16.1\n",
    "# 노트북 셀에서 패키지 설치\n",
    "!pip install -U langchain-huggingface langchain-chroma langchain-core langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351cc344-21fb-42d4-89b8-72e96bc727fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치 (최초 1회만 실행)\n",
    "!pip install sentence-transformers langchain langchain-community chromadb pandas tqdm torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cc412-ab48-4e28-bea2-b0510d2e82be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6ac20-febb-4dcb-a057-b1771f89327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "!jupyter nbextension install --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382852e-2257-4f39-b760-756475a48341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69730a7-334b-45b3-85af-925ddddd97b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896deec-62db-4c64-9a26-6cdc047ae566",
   "metadata": {},
   "source": [
    "# 버그 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3575a16-2092-480a-a188-f4ff754585fd",
   "metadata": {},
   "source": [
    "### 1) gpu 미사용 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0ac13-1ee3-4527-b4d1-2cdec3c4cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. 기존 패키지 제거 시작\")\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "print(\"기존 패키지 제거 완료\")\n",
    "print(\"pip 캐시 초기화\")\n",
    "!pip cache purge\n",
    "print(\"2. CUDA 버전 설치 시작 (상세 로그 활성화)\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --verbose\n",
    "print(\"설치 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ae170-5413-48b4-ad3e-7f9dc8ce6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"확인\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f619fc8-0160-4721-be63-af4438605443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1be2cd-314d-4b12-84e7-00a82121a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_status_safe():\n",
    "    \"\"\"GPU 상태를 안전하게 진단합니다(타임아웃 및 오류 처리 포함)\"\"\"\n",
    "    print(\"=== GPU 진단 시작 ===\")\n",
    "    \n",
    "    import torch\n",
    "    import platform\n",
    "    import subprocess\n",
    "    import threading\n",
    "    import time\n",
    "    \n",
    "    # 기본 정보 수집\n",
    "    print(f\"OS: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Python: {platform.python_version()}\")\n",
    "    print(f\"PyTorch: {torch.__version__}\")\n",
    "    \n",
    "    # CUDA 가용성 확인\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA 사용 가능: {cuda_available}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        try:\n",
    "            print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "            print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"CUDA 정보 수집 중 오류: {e}\")\n",
    "    else:\n",
    "        print(\"CUDA를 사용할 수 없습니다. 가능한 원인:\")\n",
    "        \n",
    "        # 타임아웃 기능이 있는 subprocess 실행 함수\n",
    "        def run_with_timeout(cmd, timeout=10):\n",
    "            result = {\"completed\": False, \"output\": \"\"}\n",
    "            \n",
    "            def target():\n",
    "                try:\n",
    "                    process = subprocess.Popen(\n",
    "                        cmd, \n",
    "                        shell=True, \n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,\n",
    "                        text=True\n",
    "                    )\n",
    "                    stdout, stderr = process.communicate(timeout=timeout)\n",
    "                    result[\"output\"] = stdout\n",
    "                    result[\"completed\"] = True\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    result[\"output\"] = f\"명령 실행 시간 초과 ({timeout}초)\"\n",
    "                except Exception as e:\n",
    "                    result[\"output\"] = f\"오류: {e}\"\n",
    "            \n",
    "            thread = threading.Thread(target=target)\n",
    "            thread.start()\n",
    "            thread.join(timeout=timeout+1)\n",
    "            \n",
    "            if thread.is_alive():\n",
    "                print(f\"경고: 명령 실행이 응답하지 않습니다. 실행을 중단합니다.\")\n",
    "                return f\"시간 초과 ({timeout}초)\"\n",
    "            \n",
    "            return result[\"output\"] if result[\"completed\"] else result[\"output\"]\n",
    "        \n",
    "        # NVIDIA GPU 존재 여부 확인 (안전한 실행)\n",
    "        if platform.system() == 'Windows':\n",
    "            print(\"Windows에서 GPU 정보 확인 중... (최대 10초 대기)\")\n",
    "            gpu_info = run_with_timeout('nvidia-smi')\n",
    "            if \"NVIDIA\" in gpu_info:\n",
    "                print(\"NVIDIA GPU 발견:\")\n",
    "                print(gpu_info[:500]) # 출력 제한\n",
    "                print(\"→ PyTorch가 CUDA와 함께 설치되지 않았을 수 있습니다.\")\n",
    "                print(\"→ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "            else:\n",
    "                print(\"→ NVIDIA GPU가 감지되지 않거나 드라이버가 설치되지 않았습니다.\")\n",
    "        elif platform.system() == 'Linux':\n",
    "            print(\"Linux에서 GPU 정보 확인 중... (최대 10초 대기)\")\n",
    "            gpu_info = run_with_timeout('nvidia-smi')\n",
    "            if \"NVIDIA\" in gpu_info:\n",
    "                print(\"NVIDIA GPU 발견:\")\n",
    "                print(gpu_info[:500]) # 출력 제한\n",
    "                print(\"→ PyTorch가 CUDA와 함께 설치되지 않았을 수 있습니다.\")\n",
    "            else:\n",
    "                print(\"→ NVIDIA GPU가 감지되지 않거나 드라이버가 설치되지 않았습니다.\")\n",
    "                \n",
    "    # PyTorch 빌드 정보 확인 (안전하게)\n",
    "    try:\n",
    "        if hasattr(torch, '__config__'):\n",
    "            if hasattr(torch.__config__, 'show'):\n",
    "                print(\"\\nPyTorch 빌드 정보:\")\n",
    "                build_info = torch.__config__.show()\n",
    "                print(build_info)\n",
    "    except Exception as e:\n",
    "        print(f\"PyTorch 빌드 정보 가져오기 실패: {e}\")\n",
    "    \n",
    "    print(\"=== GPU 진단 완료 ===\")\n",
    "    \n",
    "    # GPU 사용 가능하면 True 반환\n",
    "    return cuda_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02399bc5-b6f1-498e-a93c-542c2ca280c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "# tqdm 조건부 임포트 (ipywidgets 문제 방지)\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    print(\"✅ tqdm.notebook 성공적으로 임포트됨\")\n",
    "except ImportError:\n",
    "    from tqdm import tqdm\n",
    "    print(\"⚠️ tqdm.notebook 임포트 실패 - 일반 tqdm 사용\")\n",
    "\n",
    "# GPU 진단 실행\n",
    "print(\"\\n🖥️ GPU 진단 시작...\")\n",
    "gpu_available = check_gpu_status_safe()\n",
    "print(f\"🖥️ GPU 사용 가능: {'✅ 예' if gpu_available else '❌ 아니오'}\")\n",
    "\n",
    "# 나머지 라이브러리 조건부 임포트\n",
    "try:\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain_core.documents import Document\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    print(\"✅ LangChain 라이브러리 임포트 성공\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ 최신 LangChain 라이브러리 임포트 실패\")\n",
    "    try:\n",
    "        from langchain.embeddings import HuggingFaceEmbeddings\n",
    "        from langchain.vectorstores import Chroma\n",
    "        from langchain.schema import Document\n",
    "        from langchain.text_splitters import RecursiveCharacterTextSplitter\n",
    "        print(\"✅ 레거시 LangChain 라이브러리 임포트 성공\")\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ LangChain 라이브러리 임포트 실패: {e}\")\n",
    "        print(\"필요한 라이브러리를 설치하세요: pip install langchain langchain-chroma langchain-core langchain-huggingface langchain-text-splitters\")\n",
    "\n",
    "print(\"\\n🔍 시스템 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02238d4-ece2-4236-a62d-560664a42d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"안됨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc697c6-2031-4a28-80f8-35e3c239c325",
   "metadata": {},
   "source": [
    "## 2) 프로그래스바"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1931e13-1db3-41f5-9aa4-2ccceccd88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 패키지 설치 (별도로 실행)\n",
    "# 먼저 필요한 패키지들을 재설치합니다\n",
    "# !pip install --upgrade jupyter notebook ipywidgets\n",
    "\n",
    "# Cell 2: 설치 확인\n",
    "import ipywidgets\n",
    "print(f\"ipywidgets 버전: {ipywidgets.__version__}\")\n",
    "\n",
    "# Cell 3: 진행 표시줄 테스트\n",
    "from tqdm.notebook import tqdm\n",
    "for i in tqdm(range(10), desc=\"테스트\"):\n",
    "    import time\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd05dab-b0ec-4f26-9aca-6ec4493038bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress_bar():\n",
    "    \"\"\"환경에 상관없이 작동하는 프로그레스 바를 제공합니다.\"\"\"\n",
    "    try:\n",
    "        # 가장 기본적인 tqdm 임포트 시도\n",
    "        from tqdm import tqdm\n",
    "        return tqdm\n",
    "    except ImportError:\n",
    "        # tqdm 자체가 없는 경우 가짜 프로그레스 바 사용\n",
    "        class DummyTqdm:\n",
    "            def __init__(self, iterable=None, **kwargs):\n",
    "                self.iterable = iterable\n",
    "                self.total = len(iterable) if iterable is not None else 0\n",
    "                self.n = 0\n",
    "                self.desc = kwargs.get('desc', '')\n",
    "            \n",
    "            def __iter__(self):\n",
    "                for obj in self.iterable:\n",
    "                    yield obj\n",
    "                    self.n += 1\n",
    "                    # 10%마다 진행 상황 출력\n",
    "                    if self.total > 0 and self.n % max(1, self.total // 10) == 0:\n",
    "                        print(f\"{self.desc}: {self.n}/{self.total} ({self.n/self.total*100:.1f}%)\")\n",
    "            \n",
    "            def update(self, n=1):\n",
    "                self.n += n\n",
    "            \n",
    "            def close(self):\n",
    "                pass\n",
    "            \n",
    "            def __enter__(self):\n",
    "                return self\n",
    "            \n",
    "            def __exit__(self, *args, **kwargs):\n",
    "                self.close()\n",
    "        \n",
    "        print(\"tqdm을 로드할 수 없어 기본 진행 표시기를 사용합니다.\")\n",
    "        return DummyTqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f353de6-8a07-4106-b368-5957b263af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"됨?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee6554-f8b9-42ab-b77e-e198be0c183a",
   "metadata": {},
   "source": [
    "## 2. 설정 및 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2db6b5-88e3-46f2-bb03-77558f7b0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정\n",
    "CHROMA_PERSIST_DIR = \"chroma_db\"  # ChromaDB 저장 경로\n",
    "REVIEW_CSV_PATH = \"bgg-26m-reviews.csv\"   # 리뷰 CSV 파일 경로\n",
    "METADATA_CSV_PATH = \"boardgames_combined.csv\"  # 메타데이터 CSV 파일 경로 (없으면 None)\n",
    "\n",
    "MIN_REVIEW_LENGTH = 20  # 최소 리뷰 길이 (너무 짧은 리뷰 필터링)\n",
    "BATCH_SIZE = 1000  # 배치 처리 크기\n",
    "MODEL_NAME = \"intfloat/e5-base-v2\"  # 크로스 언어 성능이 좋은 모델\n",
    "ENRICH_TEXT = True  # 리뷰와 메타데이터를 결합하여 벡터화\n",
    "MAX_CHUNK_SIZE = 512  # 최대 청크 크기\n",
    "SAMPLE_SIZE = None  # 샘플링 크기 (None이면 전체 데이터 사용)\n",
    "\n",
    "# ID 컬럼 설정 (명시적 지정) - 수정 버전\n",
    "REVIEW_ID_COLUMN = \"ID\"  # 리뷰 데이터의 ID 컬럼 명시적 지정\n",
    "METADATA_ID_COLUMN = \"Game_Id\"  # 메타데이터의 ID 컬럼 명시적 지정 (id가 아닌 Game_Id로 수정)\n",
    "\n",
    "# 중요 메타데이터 필드 정의 수정\n",
    "IMPORTANT_META_FIELDS = [\n",
    "    'Game_Id', 'Title', 'Description', 'description_detail', 'AvgRating',\n",
    "    'minplayers', 'maxplayers', 'playingtime', 'minage', \n",
    "    'category_bert', 'CategoryType', 'boardgamemechanic', \n",
    "]\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"사용 장치: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339da4aa-ce51-4e9a-9d3a-0dfb6402e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "def validate_environment_settings():\n",
    "    \"\"\"환경 설정을 검증하고 상세 정보를 출력하는 함수\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🔍 환경 설정 검증 시작\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    validation_results = {\n",
    "        \"success\": 0,\n",
    "        \"warning\": 0,\n",
    "        \"error\": 0\n",
    "    }\n",
    "    \n",
    "    # 시스템 정보 출력\n",
    "    print(f\"🖥️  시스템 정보:\")\n",
    "    print(f\"   - Python 버전: {sys.version.split()[0]}\")\n",
    "    print(f\"   - 운영체제: {sys.platform}\")\n",
    "    print(f\"   - 현재 작업 디렉토리: {os.getcwd()}\")\n",
    "    \n",
    "    # CHROMA_PERSIST_DIR 검증\n",
    "    print(f\"\\n📁 ChromaDB 저장 경로: {CHROMA_PERSIST_DIR}\")\n",
    "    if os.path.exists(CHROMA_PERSIST_DIR):\n",
    "        print(f\"   ✅ 경로가 존재합니다.\")\n",
    "        print(f\"   - 절대 경로: {os.path.abspath(CHROMA_PERSIST_DIR)}\")\n",
    "        print(f\"   - 기존 데이터가 있을 수 있습니다.\")\n",
    "        validation_results[\"success\"] += 1\n",
    "    else:\n",
    "        print(f\"   ⚠️ 경로가 존재하지 않습니다. 실행 시 자동으로 생성됩니다.\")\n",
    "        # 쓰기 권한 확인\n",
    "        try:\n",
    "            parent_dir = os.path.dirname(CHROMA_PERSIST_DIR) or \".\"\n",
    "            if os.access(parent_dir, os.W_OK):\n",
    "                print(f\"   ✅ 디렉토리 생성 권한이 있습니다.\")\n",
    "                validation_results[\"success\"] += 1\n",
    "            else:\n",
    "                print(f\"   ❌ 디렉토리 생성 권한이 없습니다. 경로를 변경하세요.\")\n",
    "                validation_results[\"error\"] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 권한 확인 중 오류: {e}\")\n",
    "            validation_results[\"error\"] += 1\n",
    "    \n",
    "    # 리뷰 CSV 파일 검증\n",
    "    print(f\"\\n📄 리뷰 CSV 파일: {REVIEW_CSV_PATH}\")\n",
    "    if REVIEW_CSV_PATH and os.path.exists(REVIEW_CSV_PATH):\n",
    "        file_size = os.path.getsize(REVIEW_CSV_PATH) / (1024 * 1024)  # MB 단위로 변환\n",
    "        print(f\"   ✅ 파일이 존재합니다.\")\n",
    "        print(f\"   - 파일 크기: {file_size:.2f} MB\")\n",
    "        print(f\"   - 절대 경로: {os.path.abspath(REVIEW_CSV_PATH)}\")\n",
    "        # 파일 미리보기 (첫 줄)\n",
    "        try:\n",
    "            with open(REVIEW_CSV_PATH, 'r', encoding='utf-8') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                print(f\"   - 첫 줄 미리보기: {first_line[:100]}{'...' if len(first_line) > 100 else ''}\")\n",
    "            validation_results[\"success\"] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ 파일 읽기 오류: {e}\")\n",
    "            print(f\"   - UTF-8 인코딩이 아닐 수 있습니다. 코드에서 다양한 인코딩을 시도합니다.\")\n",
    "            validation_results[\"warning\"] += 1\n",
    "    else:\n",
    "        print(f\"   ❌ 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n",
    "        validation_results[\"error\"] += 1\n",
    "    \n",
    "    # 메타데이터 CSV 파일 검증\n",
    "    print(f\"\\n📄 메타데이터 CSV 파일: {METADATA_CSV_PATH}\")\n",
    "    if METADATA_CSV_PATH and os.path.exists(METADATA_CSV_PATH):\n",
    "        file_size = os.path.getsize(METADATA_CSV_PATH) / (1024 * 1024)  # MB 단위로 변환\n",
    "        print(f\"   ✅ 파일이 존재합니다.\")\n",
    "        print(f\"   - 파일 크기: {file_size:.2f} MB\")\n",
    "        print(f\"   - 절대 경로: {os.path.abspath(METADATA_CSV_PATH)}\")\n",
    "        # 파일 미리보기 (첫 줄)\n",
    "        try:\n",
    "            with open(METADATA_CSV_PATH, 'r', encoding='utf-8') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                print(f\"   - 첫 줄 미리보기: {first_line[:100]}{'...' if len(first_line) > 100 else ''}\")\n",
    "            validation_results[\"success\"] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ 파일 읽기 오류: {e}\")\n",
    "            print(f\"   - UTF-8 인코딩이 아닐 수 있습니다. 코드에서 다양한 인코딩을 시도합니다.\")\n",
    "            validation_results[\"warning\"] += 1\n",
    "    else:\n",
    "        print(f\"   ⚠️ 파일이 존재하지 않거나 지정되지 않았습니다.\")\n",
    "        print(f\"   - 메타데이터 없이 리뷰 데이터만 처리됩니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    \n",
    "    # 기타 설정 검증\n",
    "    print(f\"\\n⚙️ 기타 설정 검증:\")\n",
    "    print(f\"   - 최소 리뷰 길이: {MIN_REVIEW_LENGTH} 글자\")\n",
    "    if MIN_REVIEW_LENGTH < 10:\n",
    "        print(f\"   ⚠️ 최소 리뷰 길이가 짧습니다. 너무 짧은 리뷰가 포함될 수 있습니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    else:\n",
    "        print(f\"   ✅ 최소 리뷰 길이가 적절합니다.\")\n",
    "        validation_results[\"success\"] += 1\n",
    "    \n",
    "    print(f\"   - 배치 처리 크기: {BATCH_SIZE}\")\n",
    "    if BATCH_SIZE < 100:\n",
    "        print(f\"   ⚠️ 배치 크기가 작습니다. 처리 속도가 느릴 수 있습니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    elif BATCH_SIZE > 5000:\n",
    "        print(f\"   ⚠️ 배치 크기가 큽니다. 메모리 문제가 발생할 수 있습니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    else:\n",
    "        print(f\"   ✅ 배치 크기가 적절합니다.\")\n",
    "        validation_results[\"success\"] += 1\n",
    "    \n",
    "    print(f\"   - 임베딩 모델: {MODEL_NAME}\")\n",
    "    # 온라인 연결 확인 (HF 모델에 접근 가능한지)\n",
    "    print(f\"   ⚠️ 모델 다운로드를 위해 인터넷 연결이 필요합니다.\")\n",
    "    validation_results[\"warning\"] += 1\n",
    "    \n",
    "    print(f\"   - 최대 청크 크기: {MAX_CHUNK_SIZE}\")\n",
    "    if MAX_CHUNK_SIZE < 256:\n",
    "        print(f\"   ⚠️ 청크 크기가 작습니다. 컨텍스트가 불충분할 수 있습니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    elif MAX_CHUNK_SIZE > 1024:\n",
    "        print(f\"   ⚠️ 청크 크기가 큽니다. 처리 속도가 느릴 수 있습니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    else:\n",
    "        print(f\"   ✅ 청크 크기가 적절합니다.\")\n",
    "        validation_results[\"success\"] += 1\n",
    "    \n",
    "    print(f\"   - 리뷰와 메타데이터 결합: {'예' if ENRICH_TEXT else '아니오'}\")\n",
    "    if ENRICH_TEXT:\n",
    "        print(f\"   ✅ 리뷰와 메타데이터를 결합하여 더 풍부한 벡터 정보를 생성합니다.\")\n",
    "        validation_results[\"success\"] += 1\n",
    "    else:\n",
    "        print(f\"   ⚠️ 리뷰 데이터만 벡터화합니다. 메타데이터 정보가 포함되지 않습니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    \n",
    "    # ID 컬럼 설정 검증\n",
    "    print(f\"\\n🔑 ID 컬럼 설정:\")\n",
    "    print(f\"   - 리뷰 데이터 ID 컬럼: {REVIEW_ID_COLUMN}\")\n",
    "    print(f\"   - 메타데이터 ID 컬럼: {METADATA_ID_COLUMN}\")\n",
    "    print(f\"   ⚠️ ID 컬럼은 실제 파일에서 다시 확인됩니다.\")\n",
    "    validation_results[\"warning\"] += 1\n",
    "    \n",
    "    # CUDA 가용성 검사\n",
    "    print(f\"\\n🖥️ 하드웨어 가속 상태:\")\n",
    "    print(f\"   - 선택된 장치: {device}\")\n",
    "    if device == \"cuda\":\n",
    "        print(f\"   ✅ CUDA 사용 가능! GPU 가속으로 처리됩니다.\")\n",
    "        # CUDA 상세 정보\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        device_count = torch.cuda.device_count() if cuda_available else 0\n",
    "        current_device = torch.cuda.current_device() if cuda_available else -1\n",
    "        device_name = torch.cuda.get_device_name(current_device) if cuda_available and device_count > 0 else \"N/A\"\n",
    "        \n",
    "        print(f\"   - CUDA 버전: {torch.version.cuda if hasattr(torch.version, 'cuda') else 'N/A'}\")\n",
    "        print(f\"   - GPU 개수: {device_count}\")\n",
    "        print(f\"   - 현재 GPU: {device_name}\")\n",
    "        \n",
    "        # 메모리 정보 출력 시도\n",
    "        try:\n",
    "            if cuda_available and device_count > 0:\n",
    "                free_mem, total_mem = torch.cuda.mem_get_info(current_device)\n",
    "                free_mem_gb = free_mem / (1024**3)\n",
    "                total_mem_gb = total_mem / (1024**3)\n",
    "                print(f\"   - GPU 메모리: {free_mem_gb:.2f}GB 가용 / {total_mem_gb:.2f}GB 전체\")\n",
    "        except:\n",
    "            print(f\"   - GPU 메모리 정보: 확인 불가\")\n",
    "        \n",
    "        validation_results[\"success\"] += 1\n",
    "    else:\n",
    "        print(f\"   ⚠️ CPU만 사용 가능합니다. 처리 속도가 느릴 수 있습니다.\")\n",
    "        validation_results[\"warning\"] += 1\n",
    "    \n",
    "    # 총평\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"📊 환경 설정 검증 결과:\")\n",
    "    print(f\"   ✅ 성공: {validation_results['success']}개\")\n",
    "    print(f\"   ⚠️ 경고: {validation_results['warning']}개\")\n",
    "    print(f\"   ❌ 오류: {validation_results['error']}개\")\n",
    "    \n",
    "    if validation_results[\"error\"] > 0:\n",
    "        print(\"\\n⛔ 심각한 문제가 발견되었습니다. 위 오류를 해결한 후 다시 시도하세요.\")\n",
    "    elif validation_results[\"warning\"] > 0:\n",
    "        print(\"\\n⚠️ 일부 경고가 있지만 실행은 가능합니다. 위 경고를 검토하세요.\")\n",
    "    else:\n",
    "        print(\"\\n✅ 모든 설정이 유효합니다. 실행 준비가 완료되었습니다.\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return validation_results[\"error\"] == 0  # 오류가 없으면 True 반환\n",
    "\n",
    "# 검증 함수 실행\n",
    "is_valid = validate_environment_settings()\n",
    "if is_valid:\n",
    "    print(\"환경 설정이 유효합니다. 다음 단계로 진행할 수 있습니다.\")\n",
    "else:\n",
    "    print(\"환경 설정에 문제가 있습니다. 위의 오류를 수정한 후 다시 시도하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c67a6c-2c01-47b3-a2ce-47d3e409ab71",
   "metadata": {},
   "source": [
    "## 3. 메타데이터 로드 및 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0dd98f-a805-432c-9ac3-dbc5fc1b1f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0027bb70-655c-4093-a20e-c51091d678c5",
   "metadata": {},
   "source": [
    "## 4. CSV 리뷰 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02e2bd-b147-4725-803f-423c8b28935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import sys # sys import 추가\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed # as_completed 추가\n",
    "import ast # 문자열 리스트 파싱을 위해 추가\n",
    "\n",
    "# tqdm 설정 (콘솔 또는 노트북 환경 자동 감지 시도)\n",
    "try:\n",
    "    # 'get_ipython'에 대한 정의 오류 방지\n",
    "    ipython_shell = get_ipython()\n",
    "    shell = ipython_shell.__class__.__name__\n",
    "    if shell == 'ZMQInteractiveShell':\n",
    "        from tqdm.notebook import tqdm as tqdm_notebook # Jupyter 환경\n",
    "    else:\n",
    "        from tqdm import tqdm as tqdm_notebook # 다른 IPython 환경 (예: 터미널)\n",
    "except NameError:\n",
    "    from tqdm import tqdm as tqdm_notebook # IPython이 아닌 환경\n",
    "\n",
    "# 기존 임포트 유지\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- 설정 변수 ---\n",
    "CHROMA_PERSIST_DIR = \"./chroma_db_integrated4\" # 디렉토리 이름 변경 가능\n",
    "REVIEW_CSV_PATH = \"bgg-26m-reviews.csv\"\n",
    "METADATA_CSV_PATH = \"boardgames_combined.csv\"\n",
    "MIN_REVIEW_LENGTH = 20\n",
    "BATCH_SIZE = 500 # add_documents_to_vectorstore 에서 사용할 배치 크기\n",
    "MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
    "ENRICH_TEXT = True\n",
    "MAX_CHUNK_SIZE = 512\n",
    "SAMPLE_SIZE = None # None이면 전체 데이터 처리\n",
    "CHECKPOINT_DIR = \"./checkpoints4\" # 체크포인트 저장 디렉토리\n",
    "\n",
    "REVIEW_ID_COLUMN = \"ID\" # 리뷰 파일의 게임 ID 컬럼명\n",
    "METADATA_ID_COLUMN = \"Game_Id\" # 메타데이터 파일의 게임 ID 컬럼명\n",
    "\n",
    "IMPORTANT_META_FIELDS = [\n",
    "    'Game_Id', 'Title', 'Description', 'description_detail', 'AvgRating',\n",
    "    'minplayers', 'maxplayers', 'playingtime', 'minage',\n",
    "    'category_bert', 'CategoryType', 'boardgamemechanic',\n",
    "    'averageweight'\n",
    "]\n",
    "\n",
    "# --- E5 모델용 포맷 함수 ---\n",
    "def format_query(user_query):\n",
    "    \"\"\"E5 모델용 쿼리 포맷팅\"\"\"\n",
    "    return f\"query: {user_query.strip()}\"\n",
    "\n",
    "def format_passage(doc_text):\n",
    "    \"\"\"E5 모델용 문서(Passage) 포맷팅\"\"\"\n",
    "    return f\"passage: {doc_text.strip()}\"\n",
    "\n",
    "\n",
    "# --- 1. GPU 진단 및 설정 함수 ---\n",
    "def check_gpu_status():\n",
    "    \"\"\"GPU 상태를 자세히 진단하고 문제점을 보고합니다.\"\"\"\n",
    "    print(\"\\n=== GPU 진단 시작 ===\")\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA 사용 가능: {cuda_available}\")\n",
    "\n",
    "    if cuda_available:\n",
    "        print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "        print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            try:\n",
    "                free_mem, total_mem = torch.cuda.mem_get_info(i)\n",
    "                free_mem_gb = free_mem / (1024**3)\n",
    "                total_mem_gb = total_mem / (1024**3)\n",
    "                print(f\"  GPU {i} 메모리: {free_mem_gb:.2f}GB 가용 / {total_mem_gb:.2f}GB 전체\")\n",
    "            except Exception as e:\n",
    "                print(f\"  GPU {i} 메모리 정보를 가져올 수 없습니다: {e}\")\n",
    "    else:\n",
    "        print(\"CUDA를 사용할 수 없습니다.\")\n",
    "        # (추가적인 원인 분석 로직은 필요 시 원래 코드에서 가져올 수 있음)\n",
    "    print(\"=== GPU 진단 완료 ===\")\n",
    "    return cuda_available\n",
    "\n",
    "# --- 2. 프로그레스 바 설정 함수 ---\n",
    "def setup_progress_bar():\n",
    "    \"\"\"환경에 맞는 tqdm 진행 표시줄을 반환합니다.\"\"\"\n",
    "    print(\"\\n=== 프로그레스 바 설정 시작 ===\")\n",
    "    progress_bar = tqdm_notebook\n",
    "    try:\n",
    "        ipython_shell = get_ipython()\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            print(\"Jupyter Notebook 환경 감지. tqdm.notebook 사용.\")\n",
    "            from tqdm.notebook import tqdm as progress_bar\n",
    "            # 간단한 테스트\n",
    "            try:\n",
    "                for _ in progress_bar(range(2), desc=\"프로그레스 바 테스트\", leave=False):\n",
    "                    time.sleep(0.01)\n",
    "                print(\"✅ 노트북 프로그레스 바 작동 확인.\")\n",
    "            except Exception as e:\n",
    "                 print(f\"⚠️ 노트북 프로그레스 바 테스트 중 오류: {e}. 표준 tqdm 사용.\")\n",
    "                 from tqdm import tqdm as progress_bar\n",
    "            return progress_bar\n",
    "        else: # 다른 IPython 환경 (터미널 등)\n",
    "             print(\"IPython 터미널 환경 감지. 표준 tqdm 사용.\")\n",
    "             from tqdm import tqdm as progress_bar\n",
    "    except NameError:\n",
    "        print(\"표준 Python 환경 감지. 표준 tqdm 사용.\")\n",
    "        from tqdm import tqdm as progress_bar\n",
    "    finally:\n",
    "        print(\"=== 프로그레스 바 설정 완료 ===\")\n",
    "        return progress_bar # 최종 결정된 progress_bar 반환\n",
    "        \n",
    "# --- 3. 체크포인트 관리 시스템 ---\n",
    "class CheckpointManager:\n",
    "    def __init__(self, pipeline_id=\"default\"):\n",
    "        self.pipeline_id = pipeline_id\n",
    "        os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "        self.checkpoint_file = os.path.join(CHECKPOINT_DIR, f\"{pipeline_id}_checkpoint.json\")\n",
    "        self.state = self._load_state()\n",
    "        # Load 시 set으로 변환되었는지 확인\n",
    "        if isinstance(self.state.get(\"processed_ids\", {}).get(\"review_ids\"), list) or \\\n",
    "           isinstance(self.state.get(\"processed_ids\", {}).get(\"document_ids\"), list):\n",
    "             self._convert_ids_to_set()\n",
    "\n",
    "    def _convert_ids_to_set(self):\n",
    "        \"\"\"로드된 ID 리스트를 집합(set)으로 변환\"\"\"\n",
    "        if \"processed_ids\" in self.state:\n",
    "            for id_type in self.state[\"processed_ids\"]:\n",
    "                 if isinstance(self.state[\"processed_ids\"][id_type], list):\n",
    "                      # print(f\"Converting processed_ids['{id_type}'] to set...\") # 디버깅용\n",
    "                      self.state[\"processed_ids\"][id_type] = set(self.state[\"processed_ids\"][id_type])\n",
    "\n",
    "    def _load_state(self):\n",
    "        \"\"\"기존 체크포인트 상태 로드\"\"\"\n",
    "        if os.path.exists(self.checkpoint_file):\n",
    "            try:\n",
    "                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:\n",
    "                    loaded_state = json.load(f)\n",
    "                # 로드 후 바로 set으로 변환\n",
    "                if \"processed_ids\" in loaded_state:\n",
    "                    for id_type in loaded_state[\"processed_ids\"]:\n",
    "                        if isinstance(loaded_state[\"processed_ids\"][id_type], list):\n",
    "                             loaded_state[\"processed_ids\"][id_type] = set(loaded_state[\"processed_ids\"][id_type])\n",
    "                return loaded_state\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"⚠️ 체크포인트 파일 JSON 디코딩 오류 ({self.checkpoint_file}): {e}\")\n",
    "                print(\"   -> 파일을 백업하고 새로 시작합니다.\")\n",
    "                self._backup_corrupted_checkpoint()\n",
    "                return self._init_state()\n",
    "        \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 체크포인트 파일 로드 중 예상치 못한 오류 ({self.checkpoint_file}): {str(e)}\")\n",
    "                self._backup_corrupted_checkpoint()\n",
    "                return self._init_state()\n",
    "                \n",
    "        else:\n",
    "            return self._init_state()\n",
    "\n",
    "    def _backup_corrupted_checkpoint(self):\n",
    "        \"\"\"손상된 체크포인트 파일을 백업\"\"\"\n",
    "        if os.path.exists(self.checkpoint_file):\n",
    "            backup_file = f\"{self.checkpoint_file}.corrupted_{int(time.time())}.bak\"\n",
    "            try : \n",
    "                os.rename(self.checkpoint_file, backup_file)\n",
    "                print(f\"   손상된 파일 백업됨: {backup_file}\")\n",
    "            except Exception as backup_e:\n",
    "                print(f\"   ⚠️ 손상된 파일 백업 실패: {backup_e}\")\n",
    "            \n",
    "\n",
    "    def _init_state(self):\n",
    "        \"\"\"새 체크포인트 상태 초기화\"\"\"\n",
    "        print(f\"새 체크포인트 상태 초기화: {self.pipeline_id}\")\n",
    "        return {\n",
    "            \"pipeline_id\": self.pipeline_id,\n",
    "            \"start_time\": time.time(),\n",
    "            \"last_update\": time.time(),\n",
    "            \"stages\": {\n",
    "                # 파이프라인 단계에 맞춰 수정\n",
    "                \"metadata_loaded\": False, \"reviews_processed\": False, \"data_enriched\": False,\n",
    "                \"documents_created\": False, \"documents_split\": False, \"vectorstore_setup\": False,\n",
    "                \"passage_formatting_applied\": False, # E5 포맷팅 단계 추가\n",
    "                \"documents_added\": False, \"vectorstore_tested\": False\n",
    "            },\n",
    "            \"counters\": {\n",
    "                \"metadata_count\": 0, \"reviews_processed\": 0, \"enriched_count\": 0,\n",
    "                \"documents_created\": 0, \"documents_split\": 0, \"documents_added\": 0,\n",
    "                \"last_added_batch_index\": -1\n",
    "            },\n",
    "            \"processed_ids\": {\n",
    "                \"review_ids\": set(), # 리뷰 처리 중복 방지용\n",
    "                \"document_ids\": set() # 벡터 저장소 추가 중복 방지용 (Chroma ID 기준)\n",
    "            },\n",
    "            # 추가 정보 저장 가능 (예: 로드된 파일 경로)\n",
    "            \"source_files\": {\n",
    "                \"metadata_file\": None,\n",
    "                \"review_file\": None\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"현재 상태를 파일에 저장 (set을 list로 변환)\"\"\"\n",
    "        save_state = self.state.copy()\n",
    "        # JSON 저장을 위해 set을 list로 변환\n",
    "        save_state[\"processed_ids\"] = {\n",
    "            key: list(val) for key, val in self.state[\"processed_ids\"].items()\n",
    "        }\n",
    "        save_state[\"last_update\"] = time.time() # 저장 시점 업데이트\n",
    "\n",
    "        try:\n",
    "            # 임시 파일에 먼저 저장\n",
    "            temp_file = self.checkpoint_file + \".tmp\"\n",
    "            with open(temp_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(save_state, f, indent=4, ensure_ascii=False)\n",
    "            # 저장 성공 시 원본 파일로 변경 (원자적 연산 시도)\n",
    "            os.replace(temp_file, self.checkpoint_file)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 체크포인트 저장 오류 ({self.checkpoint_file}): {e}\")\n",
    "            # 임시 파일 삭제 시도\n",
    "            if os.path.exists(temp_file):\n",
    "                 try: os.remove(temp_file)\n",
    "                 except: pass\n",
    "\n",
    "    def update_stage(self, stage, status=True):\n",
    "        \"\"\"단계 완료 상태 업데이트\"\"\"\n",
    "        if stage in self.state[\"stages\"]:\n",
    "            # 상태가 변경되었을 때만 저장\n",
    "            if self.state[\"stages\"][stage] != status:\n",
    "                 self.state[\"stages\"][stage] = status\n",
    "                 self.save()\n",
    "        else:\n",
    "             print(f\"⚠️ 경고: 존재하지 않는 체크포인트 단계 업데이트 시도 - {stage}\")\n",
    "\n",
    "    def update_counter(self, counter, value):\n",
    "        \"\"\"카운터 값 업데이트\"\"\"\n",
    "        if counter in self.state[\"counters\"]:\n",
    "            # 값이 변경되었을 때만 저장\n",
    "            if self.state[\"counters\"][counter] != value:\n",
    "                 self.state[\"counters\"][counter] = value\n",
    "                 self.save()\n",
    "        else:\n",
    "             print(f\"⚠️ 경고: 존재하지 않는 체크포인트 카운터 업데이트 시도 - {counter}\")\n",
    "\n",
    "    # def increment_counter(self, counter, increment=1):\n",
    "    #     \"\"\"카운터 증가\"\"\"\n",
    "    #     if counter in self.state[\"counters\"]:\n",
    "    #         self.state[\"counters\"][counter] += increment\n",
    "    #         # 증가는 빈번할 수 있으므로 매번 save하지 않고,\n",
    "    #         # 단계 완료 시 또는 주기적으로 save하는 것이 효율적일 수 있음\n",
    "    #         # 여기서는 일단 저장\n",
    "    #         self.save()\n",
    "\n",
    "    def is_stage_completed(self, stage):\n",
    "        \"\"\"단계가 완료되었는지 확인\"\"\"\n",
    "        return self.state[\"stages\"].get(stage, False)\n",
    "        \n",
    "    def add_processed_ids(self, id_type, ids):\n",
    "        \"\"\"처리된 ID 추가 (set 업데이트 후 저장)\"\"\"\n",
    "        if id_type in self.state[\"processed_ids\"]:\n",
    "            if not isinstance(ids, (list, set, tuple)): # tuple 추가\n",
    "                ids = [ids]\n",
    "            # None 값 제거 및 문자열 변환\n",
    "            str_ids = {str(id_val) for id_val in ids if id_val is not None}\n",
    "            if not str_ids: return # 추가할 유효한 ID가 없으면 반환\n",
    "\n",
    "            initial_len = len(self.state[\"processed_ids\"][id_type])\n",
    "            self.state[\"processed_ids\"][id_type].update(str_ids)\n",
    "            # 실제 ID가 추가되었을 때만 저장\n",
    "            if len(self.state[\"processed_ids\"][id_type]) > initial_len:\n",
    "                self.save()\n",
    "        else:\n",
    "            print(f\"⚠️ 경고: 존재하지 않는 ID 타입에 ID 추가 시도 - {id_type}\")\n",
    "\n",
    "    def is_id_processed(self, id_type, id_value):\n",
    "        \"\"\"ID가 이미 처리되었는지 확인\"\"\"\n",
    "        if id_type in self.state[\"processed_ids\"] and id_value is not None:\n",
    "            return str(id_value) in self.state[\"processed_ids\"][id_type]\n",
    "        return False\n",
    "\n",
    "    def get_processed_ids_count(self, id_type):\n",
    "        \"\"\"처리된 ID 개수 반환\"\"\"\n",
    "        return len(self.state.get(\"processed_ids\", {}).get(id_type, set()))\n",
    "\n",
    "    def get_resume_info(self):\n",
    "        \"\"\"재개 정보 얻기\"\"\"\n",
    "        completed_stages = [s for s, status in self.state.get(\"stages\", {}).items() if status]\n",
    "        import datetime\n",
    "        last_update_ts = self.state.get(\"last_update\", 0)\n",
    "        last_update_str = \"N/A\"\n",
    "        if last_update_ts:\n",
    "            try:\n",
    "                last_update_str = datetime.datetime.fromtimestamp(last_update_ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            except ValueError: # 유효하지 않은 타임스탬프 처리\n",
    "                pass\n",
    "\n",
    "        counters = self.state.get(\"counters\", {})\n",
    "        last_added_batch_idx = counters.get(\"last_added_batch_index\", -1)\n",
    "\n",
    "        return {\n",
    "            \"can_resume\": len(completed_stages) > 0 or last_added_batch_idx >= 0,\n",
    "            \"completed_stages\": completed_stages,\n",
    "            \"counters\": counters,\n",
    "            \"processed_counts\": {\n",
    "                \"reviews\": self.get_processed_ids_count(\"review_ids\"),\n",
    "                \"documents\": self.get_processed_ids_count(\"document_ids\"),\n",
    "            },\n",
    "            \"last_update\": last_update_str,\n",
    "            \"last_added_batch_index\": last_added_batch_idx\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"체크포인트 상태 초기화\"\"\"\n",
    "        print(f\"🔄 체크포인트 초기화 중: {self.checkpoint_file}\")\n",
    "        self.state = self._init_state()\n",
    "        self.save()\n",
    "        print(\"✅ 체크포인트가 초기화되었습니다.\")\n",
    "\n",
    "    def update_source_file(self, file_type, file_path):\n",
    "        \"\"\"소스 파일 경로 저장\"\"\"\n",
    "        if file_type in self.state.get(\"source_files\", {}):\n",
    "             if self.state[\"source_files\"][file_type] != file_path:\n",
    "                  self.state[\"source_files\"][file_type] = file_path\n",
    "                  self.save()\n",
    "\n",
    "\n",
    "# --- 4. 병렬 처리 관리자 ---\n",
    "class ParallelProcessor:\n",
    "    def __init__(self, use_processes=False, max_workers=None):\n",
    "        self.use_processes = use_processes\n",
    "        cpu_count = multiprocessing.cpu_count()\n",
    "        self.max_workers = max_workers if max_workers is not None else max(1, cpu_count - 1)\n",
    "        print(f\"병렬 처리 설정: {'프로세스' if use_processes else '스레드'} 모드, {self.max_workers}개 워커\")\n",
    "        self.executor_class = ProcessPoolExecutor if self.use_processes else ThreadPoolExecutor\n",
    "\n",
    "    def process_batch(self, func, items, desc=\"병렬 처리 중\", chunksize=1, **kwargs):\n",
    "        \"\"\"항목 배치를 병렬로 처리 (개선된 버전)\"\"\"\n",
    "        if not items: return []\n",
    "\n",
    "        if len(items) < self.max_workers * 2:\n",
    "             print(f\"ℹ️ 항목 수가 적어 ({len(items)}개) 직렬 처리합니다.\")\n",
    "             results = []\n",
    "             for item in tqdm_notebook(items, desc=f\"{desc} (직렬)\"):\n",
    "                  try:\n",
    "                      results.append(func(item, **kwargs) if kwargs else func(item))\n",
    "                  except Exception as e:\n",
    "                      # 직렬 처리 오류 시 인덱스 정보 추가\n",
    "                      item_info = f\"항목 {items.index(item)}\" if isinstance(items, list) else \"항목\"\n",
    "                      print(f\"⚠️ {item_info} 처리 중 오류 발생 (직렬): {e}\")\n",
    "                      results.append(None)\n",
    "             return results\n",
    "\n",
    "        results = [None] * len(items)\n",
    "        futures_map = {} # Future -> original index 매핑\n",
    "\n",
    "        with self.executor_class(max_workers=self.max_workers) as executor:\n",
    "            # submit 사용 시 인덱스와 함께 전달\n",
    "            for i, item in enumerate(items):\n",
    "                 future = executor.submit(func, item, **kwargs) if kwargs else executor.submit(func, item)\n",
    "                 futures_map[future] = i\n",
    "\n",
    "            with tqdm_notebook(total=len(items), desc=desc) as pbar:\n",
    "                for future in as_completed(futures_map):\n",
    "                    original_index = futures_map[future]\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        results[original_index] = result\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ 병렬 작업 오류 (원본 인덱스 {original_index}): {e}\")\n",
    "                        # 결과는 None으로 유지됨\n",
    "                    finally:\n",
    "                         pbar.update(1)\n",
    "\n",
    "        error_count = sum(1 for r in results if r is None) # None 결과 개수 확인\n",
    "        if error_count > 0:\n",
    "            print(f\"⚠️ 병렬 처리 중 {error_count}/{len(items)}개 항목에서 오류가 발생했을 수 있습니다.\")\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# --- 기존 함수 정의 (필요에 따라 내부 수정) ---\n",
    "\n",
    "# load_game_metadata (체크포인트 로직 추가)\n",
    "def load_game_metadata(metadata_file=METADATA_CSV_PATH, checkpoint_mgr=None, progress_bar=tqdm_notebook):\n",
    "    \"\"\"보드게임 메타데이터 로드 (체크포인트 지원 시도)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📚 1단계: 메타데이터 로드\")\n",
    "    print(\"=\"*50)\n",
    "    stage_name = \"metadata_loaded\"\n",
    "    reload_needed = True # 기본적으로 리로드 필요\n",
    "\n",
    "    # --- 체크포인트 확인 ---\n",
    "    # 메타데이터는 일반적으로 다시 로드하는 것이 안전하므로,\n",
    "    # 여기서는 완료 여부만 확인하고 실제 로드는 항상 수행하도록 할 수 있음.\n",
    "    # 또는, 로드된 파일 경로가 같은지 확인하는 로직 추가 가능.\n",
    "    if checkpoint_mgr:\n",
    "        if checkpoint_mgr.is_stage_completed(stage_name):\n",
    "             loaded_file = checkpoint_mgr.state[\"source_files\"].get(\"metadata_file\")\n",
    "             if loaded_file == metadata_file:\n",
    "                 print(f\"✅ 메타데이터 '{metadata_file}'는 이전 실행에서 이미 로드되었습니다.\")\n",
    "                 print(f\"   저장된 카운트: {checkpoint_mgr.state['counters']['metadata_count']}\")\n",
    "                 # 실제 데이터를 로드하는 기능은 없으므로, 재로드하거나 여기서 None 반환\n",
    "                 # 여기서는 재로드 진행\n",
    "                 print(\"   (체크포인트 확인했지만, 데이터 재로드를 진행합니다)\")\n",
    "             else:\n",
    "                  print(f\"⚠️ 이전 로드 파일({loaded_file})과 현재 파일({metadata_file})이 다릅니다. 재로드합니다.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if not os.path.exists(metadata_file):\n",
    "        print(f\"❌ 파일 없음: {metadata_file}\"); return None, None\n",
    "    # ... (파일 정보 출력, 인코딩 시도, ID 컬럼 찾기, 변환, 중복 제거 로직은 이전과 동일) ...\n",
    "    file_size = os.path.getsize(metadata_file) / (1024 * 1024)\n",
    "    print(f\"📁 파일: {metadata_file} ({file_size:.2f} MB)\")\n",
    "    metadata_df = None\n",
    "    encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']\n",
    "    for encoding in progress_bar(encodings, desc=\"메타 인코딩 테스트\"):\n",
    "         try:\n",
    "             metadata_df = pd.read_csv(metadata_file, encoding=encoding)\n",
    "             print(f\"  ✅ {encoding} 로드 성공!\"); break\n",
    "         except: continue\n",
    "    if metadata_df is None: print(\"❌ 메타 로드 실패.\"); return None, None\n",
    "\n",
    "    id_column = METADATA_ID_COLUMN if METADATA_ID_COLUMN in metadata_df.columns else None\n",
    "    if not id_column:\n",
    "        id_candidates = ['id', 'ID', 'game_id', 'gameid', 'item_id']\n",
    "        for candidate in id_candidates:\n",
    "             matches = [c for c in metadata_df.columns if c.lower() == candidate.lower()]\n",
    "             if matches: id_column = matches[0]; break\n",
    "    if not id_column: print(\"⚠️ ID 컬럼 못찾음. 인덱스 사용.\"); metadata_df['generated_id'] = metadata_df.index.astype(str); id_column = 'generated_id'\n",
    "    else: print(f\"✅ ID 컬럼: '{id_column}'\")\n",
    "\n",
    "    metadata_df[id_column] = metadata_df[id_column].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "    dups = metadata_df.duplicated(subset=[id_column]).sum()\n",
    "    if dups > 0: print(f\"   ⚠️ 중복 ID {dups}개 발견. 첫 값 유지.\"); metadata_df = metadata_df.drop_duplicates(subset=[id_column], keep='first')\n",
    "\n",
    "    print(\"🔄 사전 생성 중...\")\n",
    "    metadata_dict = metadata_df.set_index(id_column).to_dict('index')\n",
    "    metadata_count = len(metadata_dict)\n",
    "\n",
    "    if checkpoint_mgr:\n",
    "        checkpoint_mgr.update_counter(\"metadata_count\", metadata_count)\n",
    "        checkpoint_mgr.update_stage(stage_name, True)\n",
    "        print(f\"✅ 체크포인트 업데이트: {stage_name}=True, count={metadata_count}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"✅ 로드 완료: {metadata_count:,}개 게임 ({total_time:.2f}초)\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    return metadata_dict, id_column\n",
    "\n",
    "# preprocess_reviews (체크포인트 로직 추가)\n",
    "def preprocess_reviews(csv_path=REVIEW_CSV_PATH, checkpoint_mgr=None, progress_bar=tqdm_notebook):\n",
    "    \"\"\"CSV 리뷰 데이터 로드 및 전처리 (체크포인트 지원 시도)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"📝 2단계: 리뷰 데이터 처리\")\n",
    "    print(\"=\"*70)\n",
    "    stage_name = \"reviews_processed\"\n",
    "\n",
    "    # --- 체크포인트 확인 ---\n",
    "    if checkpoint_mgr:\n",
    "         if checkpoint_mgr.is_stage_completed(stage_name):\n",
    "             loaded_file = checkpoint_mgr.state[\"source_files\"].get(\"review_file\")\n",
    "             if loaded_file == csv_path:\n",
    "                  processed_count = checkpoint_mgr.state[\"counters\"][\"reviews_processed\"]\n",
    "                  saved_id_count = checkpoint_mgr.get_processed_ids_count(\"review_ids\")\n",
    "                  print(f\"✅ 리뷰 파일 '{csv_path}'는 이전 실행에서 이미 처리되었습니다.\")\n",
    "                  print(f\"   저장된 처리 카운트: {processed_count:,}, 저장된 ID 수: {saved_id_count:,}\")\n",
    "                  # 여기서 처리를 건너뛰려면, 이전 결과를 로드하는 매커니즘 필요.\n",
    "                  # 여기서는 ID 기반 중복 처리를 강화하는 방향으로 진행.\n",
    "                  print(\"   (체크포인트 확인. ID 기반 중복 처리를 사용하여 진행합니다)\")\n",
    "             else:\n",
    "                  print(f\"⚠️ 이전 처리 파일({loaded_file})과 현재 파일({csv_path})이 다릅니다. 새로 처리합니다.\")\n",
    "                  # 이전 ID 정보가 유효하지 않으므로 초기화 필요 시 고려\n",
    "                  # checkpoint_mgr.state[\"processed_ids\"][\"review_ids\"] = set()\n",
    "                  # checkpoint_mgr.save()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"❌ CSV 파일을 찾을 수 없습니다: {csv_path}\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return None, None, None\n",
    "\n",
    "    print(f\"📂 리뷰 데이터 파일: {csv_path}\")\n",
    "    # (파일 크기 확인 등 유지)\n",
    "\n",
    "    df = None\n",
    "    try:\n",
    "        # (인코딩 시도 로직 유지, SAMPLE_SIZE 적용 유지)\n",
    "        encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']\n",
    "        encoding_used = None\n",
    "        for encoding in progress_bar(encodings, desc=\"리뷰 파일 인코딩 테스트\"):\n",
    "            try:\n",
    "                 print(f\"   🔍 {encoding} 인코딩으로 시도...\")\n",
    "                 # 샘플 로드로 인코딩 확인\n",
    "                 pd.read_csv(csv_path, nrows=5, encoding=encoding)\n",
    "                 # 로드\n",
    "                 read_kwargs = {'encoding': encoding, 'on_bad_lines': 'warn'}\n",
    "                 if SAMPLE_SIZE:\n",
    "                      print(f\"\\n⚠️ 테스트 모드: 처음 {SAMPLE_SIZE:,}행만 읽습니다.\")\n",
    "                      read_kwargs['nrows'] = SAMPLE_SIZE\n",
    "                 else:\n",
    "                      print(f\"\\n📂 전체 데이터 로드 시도...\")\n",
    "                 try:\n",
    "                     df = pd.read_csv(csv_path, **read_kwargs)\n",
    "                 except pd.errors.ParserError as pe:\n",
    "                     print(f\"   ⚠️ 파싱 오류 ({encoding}): {pe}. 오류 라인 건너뛰고 재시도.\")\n",
    "                     read_kwargs['on_bad_lines'] = 'skip'\n",
    "                     df = pd.read_csv(csv_path, **read_kwargs)\n",
    "\n",
    "                 print(f\"   ✅ {encoding} 로드 성공.\")\n",
    "                 encoding_used = encoding\n",
    "                 break\n",
    "            except UnicodeDecodeError:\n",
    "                 print(f\"   ❌ {encoding} 인코딩 실패\")\n",
    "                 continue\n",
    "            except Exception as e:\n",
    "                 print(f\"   ❌ 로드 오류 ({encoding}): {e}\")\n",
    "                 continue\n",
    "\n",
    "        if df is None:\n",
    "            print(\"❌ CSV 파일 로드 실패.\")\n",
    "            if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "            return None, None, None\n",
    "\n",
    "        print(f\"\\n✅ CSV 로드 성공: {len(df):,}행\")\n",
    "\n",
    "        # (리뷰 컬럼 찾기, ID 컬럼 찾기 및 변환 로직 유지)\n",
    "        review_column_candidates = ['comment', 'review', 'text', 'content', 'review_text']\n",
    "        review_column = None\n",
    "        for col in review_column_candidates:\n",
    "            col_matches = [c for c in df.columns if c.lower() == col.lower()]\n",
    "            if col_matches:\n",
    "                review_column = col_matches[0]; break\n",
    "        if not review_column: print(\"❌ 리뷰 컬럼 찾기 실패.\"); return None, None, None\n",
    "        print(f\"✅ 리뷰 컬럼: '{review_column}'\")\n",
    "\n",
    "        id_column = None\n",
    "        id_candidates = [REVIEW_ID_COLUMN, 'id', 'ID', 'game_id', 'gameid', 'item_id', 'bgg_id', 'gid']\n",
    "        id_candidates = [c for c in id_candidates if c] # None 제거\n",
    "        for candidate in id_candidates:\n",
    "             col_matches = [c for c in df.columns if c.lower() == candidate.lower()]\n",
    "             if col_matches:\n",
    "                 id_column = col_matches[0]; break\n",
    "        if not id_column: print(\"⚠️ 리뷰 ID 컬럼 찾기 실패. 메타데이터 연결 불가.\")\n",
    "        else:\n",
    "             print(f\"✅ 리뷰 ID 컬럼: '{id_column}'\")\n",
    "             print(f\"\\n🔄 ID 컬럼 '{id_column}' 문자열 변환 및 .0 제거...\")\n",
    "             df[id_column] = df[id_column].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "        # --- 데이터 전처리 (체크포인트 ID 확인 로직 추가) ---\n",
    "        print(\"\\n🔄 리뷰 데이터 전처리 중...\")\n",
    "        initial_count = len(df)\n",
    "        processed_ids_in_this_run = set()\n",
    "        processed_rows = []\n",
    "\n",
    "        # CheckpointManager에서 이미 처리된 ID 로드\n",
    "        previously_processed_ids = set()\n",
    "        if checkpoint_mgr and id_column:\n",
    "            previously_processed_ids = checkpoint_mgr.state[\"processed_ids\"].get(\"review_ids\", set())\n",
    "            print(f\"   ℹ️ 체크포인트에서 로드된 이전 처리 리뷰 ID: {len(previously_processed_ids):,}개\")\n",
    "\n",
    "        for index, row in progress_bar(df.iterrows(), total=initial_count, desc=\"리뷰 전처리 및 필터링\"):\n",
    "             # 1. ID 기반 건너뛰기 (ID 컬럼이 있고, 체크포인트 사용 시)\n",
    "             current_id = None\n",
    "             if id_column:\n",
    "                 current_id = row[id_column]\n",
    "                 if checkpoint_mgr and checkpoint_mgr.is_id_processed(\"review_ids\", current_id):\n",
    "                     continue # 이미 처리된 ID면 건너뛰기\n",
    "\n",
    "             # 2. Null 또는 빈 리뷰 제거\n",
    "             review_text = row[review_column]\n",
    "             if pd.isna(review_text): continue\n",
    "             review_text_str = str(review_text).strip()\n",
    "             if not review_text_str: continue\n",
    "\n",
    "             # 3. 짧은 리뷰 제거\n",
    "             if len(review_text_str) < MIN_REVIEW_LENGTH: continue\n",
    "\n",
    "             # 모든 필터 통과 시 결과 리스트에 추가\n",
    "             processed_rows.append(row.to_dict()) # 딕셔너리로 변환하여 추가\n",
    "\n",
    "             # 이번 실행에서 처리된 ID 기록 (나중에 중복 제거 및 체크포인트 업데이트용)\n",
    "             if current_id is not None:\n",
    "                 processed_ids_in_this_run.add(current_id)\n",
    "\n",
    "        # 처리된 행들로 새 DataFrame 생성\n",
    "        if not processed_rows:\n",
    "             print(\"⚠️ 전처리 후 유효한 리뷰 데이터가 없습니다.\")\n",
    "             if checkpoint_mgr:\n",
    "                  # 처리는 했지만 결과가 없으므로 완료 상태는 아님\n",
    "                  checkpoint_mgr.update_stage(stage_name, False)\n",
    "                  checkpoint_mgr.update_counter(\"reviews_processed\", 0)\n",
    "             return None, review_column, id_column\n",
    "\n",
    "        processed_df = pd.DataFrame(processed_rows)\n",
    "        print(f\"✅ 기본 필터링 완료: {len(processed_df):,}행 남음\")\n",
    "\n",
    "        # 4. 내용 기반 중복 제거 (처리된 결과에 대해 수행)\n",
    "        before_dedup = len(processed_df)\n",
    "        processed_df = processed_df.drop_duplicates(subset=[review_column], keep='first')\n",
    "        print(f\"✅ 내용 기반 중복 리뷰 제거: {before_dedup - len(processed_df):,}개 제거됨\")\n",
    "\n",
    "        final_count = len(processed_df)\n",
    "        print(f\"\\n📊 전처리 후 최종 데이터 크기: {final_count:,}행\")\n",
    "\n",
    "        # --- 체크포인트 업데이트 ---\n",
    "        if checkpoint_mgr:\n",
    "            # 새로 처리된 ID들을 체크포인트에 추가\n",
    "            if id_column and processed_ids_in_this_run:\n",
    "                 newly_added_ids = processed_ids_in_this_run - previously_processed_ids\n",
    "                 if newly_added_ids:\n",
    "                     checkpoint_mgr.add_processed_ids(\"review_ids\", list(newly_added_ids))\n",
    "                     print(f\"   💾 체크포인트에 새로 처리된 리뷰 ID {len(newly_added_ids):,}개 추가됨.\")\n",
    "\n",
    "            # 카운터는 이번 실행에서 *최종적으로 남은* 행의 수로 업데이트\n",
    "            # 또는 전체 누적 카운트로 관리할 수도 있음 (여기선 최종 카운트 사용)\n",
    "            checkpoint_mgr.update_counter(\"reviews_processed\", final_count)\n",
    "            checkpoint_mgr.update_source_file(\"review_file\", csv_path)\n",
    "            # 최종 결과가 있을 때만 완료로 표시\n",
    "            checkpoint_mgr.update_stage(stage_name, final_count > 0)\n",
    "            print(f\"✅ 체크포인트 업데이트: {stage_name}={'True' if final_count > 0 else 'False'}, count={final_count}\")\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"📊 리뷰 데이터 전처리 요약:\")\n",
    "        print(f\"✅ 최종 행 수: {final_count:,}\")\n",
    "        print(f\"✅ 리뷰 컬럼: '{review_column}'\")\n",
    "        print(f\"✅ ID 컬럼: '{id_column if id_column else '없음'}'\")\n",
    "        print(f\"⏱️ 총 소요 시간: {total_time:.2f}초\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        return processed_df, review_column, id_column\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 리뷰 처리 중 오류: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        print(\"=\"*70)\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "# enrich_review_data_fixed (병렬 처리 적용)\n",
    "def enrich_review_data_fixed(review_df, metadata_dict, meta_id_column, review_id_column,\n",
    "                             parallel_mgr=None, checkpoint_mgr=None, progress_bar=tqdm_notebook):\n",
    "    \"\"\"리뷰 데이터에 게임 메타데이터 추가 (병렬 처리 및 체크포인트 시도)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🔄 3단계: 데이터 통합 (Enrichment)\")\n",
    "    print(\"=\"*70)\n",
    "    stage_name = \"data_enriched\"\n",
    "\n",
    "    # --- 체크포인트 확인 ---\n",
    "    if checkpoint_mgr and checkpoint_mgr.is_stage_completed(stage_name):\n",
    "         enriched_count = checkpoint_mgr.state[\"counters\"][\"enriched_count\"]\n",
    "         print(f\"✅ 데이터 통합 단계는 이전에 완료되었습니다 (처리된 행: {enriched_count:,}).\")\n",
    "         # 여기서 건너뛰려면 이전 결과 로드 필요. 일단 진행.\n",
    "         print(\"   (체크포인트 확인. 데이터 통합을 다시 진행합니다)\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if metadata_dict is None or review_df is None or review_df.empty:\n",
    "        print(\"❌ 메타데이터 또는 리뷰 데이터가 없어 통합 불가.\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return review_df if review_df is not None else pd.DataFrame()\n",
    "\n",
    "    if not review_id_column or review_id_column not in review_df.columns:\n",
    "        print(f\"⚠️ 리뷰 ID 컬럼 '{review_id_column}' 없어 메타데이터 통합 불가.\")\n",
    "        # ID 없으면 통합 불가, 원본 반환\n",
    "        # 체크포인트는 완료되지 않음\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return review_df\n",
    "\n",
    "    # 사용할 필드\n",
    "    fields_to_enrich = IMPORTANT_META_FIELDS\n",
    "    print(f\"   - 통합할 메타 필드: {fields_to_enrich}\")\n",
    "\n",
    "    # 데이터 통합을 위한 헬퍼 함수 (단일 행 처리)\n",
    "    def enrich_single_row(row_tuple):\n",
    "        index, row_series = row_tuple # 입력은 (인덱스, 시리즈) 형태\n",
    "        enriched_row = row_series.to_dict() # 딕셔너리로 변환\n",
    "        game_id = str(enriched_row.get(review_id_column, '')) # ID 추출 및 문자열 변환\n",
    "\n",
    "        # game_ 필드 초기화\n",
    "        for field in fields_to_enrich:\n",
    "            enriched_row[f'game_{field}'] = None\n",
    "\n",
    "        # 메타데이터 매칭 및 필드 복사\n",
    "        if game_id in metadata_dict:\n",
    "            game_meta = metadata_dict[game_id]\n",
    "            for field in fields_to_enrich:\n",
    "                if field in game_meta and pd.notna(game_meta[field]):\n",
    "                    enriched_row[f'game_{field}'] = game_meta[field]\n",
    "        # else: # 매칭 안되면 None 유지됨\n",
    "\n",
    "        return enriched_row # 처리된 딕셔너리 반환\n",
    "\n",
    "\n",
    "    # 처리할 아이템 리스트 준비 (인덱스 포함 튜플)\n",
    "    items_to_process = list(review_df.iterrows())\n",
    "\n",
    "    enriched_results = None\n",
    "    if parallel_mgr:\n",
    "        print(f\"\\n🔄 병렬 처리기로 메타데이터 통합 시작 ({len(items_to_process):,}개 행)...\")\n",
    "        # process_batch 호출\n",
    "        enriched_results = parallel_mgr.process_batch(\n",
    "            enrich_single_row,\n",
    "            items_to_process,\n",
    "            desc=\"메타데이터 통합 (병렬)\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"\\n🔄 직렬 처리로 메타데이터 통합 시작 ({len(items_to_process):,}개 행)...\")\n",
    "        enriched_results = []\n",
    "        for item in progress_bar(items_to_process, desc=\"메타데이터 통합 (직렬)\"):\n",
    "            try:\n",
    "                 enriched_results.append(enrich_single_row(item))\n",
    "            except Exception as e:\n",
    "                 print(f\"⚠️ 행 처리 중 오류: {e}\")\n",
    "                 enriched_results.append(None) # 오류 시 None 추가\n",
    "\n",
    "\n",
    "    # 결과 처리 (오류가 발생한 항목은 None일 수 있음)\n",
    "    valid_results = [res for res in enriched_results if res is not None]\n",
    "\n",
    "    if not valid_results:\n",
    "        print(\"❌ 데이터 통합 후 유효한 결과가 없습니다.\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return pd.DataFrame() # 빈 데이터프레임 반환\n",
    "\n",
    "    enriched_df = pd.DataFrame(valid_results)\n",
    "    final_count = len(enriched_df)\n",
    "\n",
    "    # 매칭률 계산 (간단히 game_Title 필드가 채워진 경우로 추정)\n",
    "    matched_count = enriched_df[f'game_{fields_to_enrich[1]}'].notna().sum() # Title 기준\n",
    "    match_pct = matched_count / final_count * 100 if final_count > 0 else 0\n",
    "    print(f\"\\n✅ 메타데이터 통합 완료: {final_count:,}개 행 처리됨\")\n",
    "    print(f\"   - 메타데이터 매칭 추정: {matched_count:,} ({match_pct:.1f}%)\")\n",
    "\n",
    "\n",
    "    # --- 체크포인트 업데이트 ---\n",
    "    if checkpoint_mgr:\n",
    "        checkpoint_mgr.update_counter(\"enriched_count\", final_count)\n",
    "        checkpoint_mgr.update_stage(stage_name, final_count > 0)\n",
    "        print(f\"✅ 체크포인트 업데이트: {stage_name}={'True' if final_count > 0 else 'False'}, count={final_count}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"⏱️ 총 처리 시간: {total_time:.2f}초\")\n",
    "    print(\"=\"*70)\n",
    "    return enriched_df\n",
    "\n",
    "\n",
    "# create_documents (병렬 처리 적용)\n",
    "def create_documents(df, review_column, enrich_text=True,\n",
    "                     parallel_mgr=None, checkpoint_mgr=None, progress_bar=tqdm_notebook):\n",
    "    \"\"\"리뷰와 메타데이터를 결합하여 Document 객체 생성 (병렬 처리)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"📄 4단계: Document 객체 생성 (enrich={enrich_text})\")\n",
    "    print(\"=\"*70)\n",
    "    stage_name = \"documents_created\"\n",
    "\n",
    "    # --- 체크포인트 확인 ---\n",
    "    if checkpoint_mgr and checkpoint_mgr.is_stage_completed(stage_name):\n",
    "        doc_count = checkpoint_mgr.state[\"counters\"][\"documents_created\"]\n",
    "        print(f\"✅ Document 생성 단계는 이전에 완료되었습니다 (생성된 문서: {doc_count:,}).\")\n",
    "        # 여기서 건너뛰려면 이전 결과 로드 필요. 일단 진행.\n",
    "        print(\"   (체크포인트 확인. Document 생성을 다시 진행합니다)\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        print(\"❌ 입력 데이터가 없어 Document 생성 불가.\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return []\n",
    "\n",
    "    # 필드 이름 매핑 (이전 코드와 동일)\n",
    "    field_display_names = {\n",
    "        'Game_Id': '게임 ID', 'Title': '게임', 'Name': '게임',\n",
    "        'Description': '설명', 'description_detail': '상세 설명',\n",
    "        'AvgRating': '평점', 'yearpublished': '출시 연도',\n",
    "        'minplayers': '최소 플레이어', 'maxplayers': '최대 플레이어',\n",
    "        'playingtime': '플레이 시간', 'minage': '최소 연령',\n",
    "        'category_bert': 'BERT 카테고리', 'CategoryType': '카테고리 타입',\n",
    "        'boardgamecategory': '장르', 'boardgamemechanic': '메커니즘',\n",
    "        'averageweight': '복잡도', 'complexity': '복잡도', 'weight': '복잡도'\n",
    "    }\n",
    "\n",
    "    # Document 생성을 위한 헬퍼 함수 (단일 행 처리)\n",
    "    def create_single_document(row_tuple):\n",
    "        index, row_series = row_tuple\n",
    "        row_dict = row_series.to_dict()\n",
    "\n",
    "        # 1. 메타데이터 구성\n",
    "        metadata = {}\n",
    "        for col, value in row_dict.items():\n",
    "            if col != review_column and pd.notna(value):\n",
    "                # 타입 변환 시도\n",
    "                if isinstance(value, (np.int64, np.int32)): metadata[col] = int(value)\n",
    "                elif isinstance(value, (np.float64, np.float32)): metadata[col] = float(value)\n",
    "                elif isinstance(value, np.bool_): metadata[col] = bool(value)\n",
    "                else: metadata[col] = str(value) # 나머지는 문자열\n",
    "\n",
    "        # 2. page_content 구성\n",
    "        page_content = \"\"\n",
    "        review_text = str(row_dict.get(review_column, ''))\n",
    "\n",
    "        if not review_text.strip():\n",
    "            return None # 리뷰 없으면 None 반환\n",
    "\n",
    "        if enrich_text:\n",
    "            combined_parts = []\n",
    "            # IMPORTANT_META_FIELDS 순회\n",
    "            for field_name in IMPORTANT_META_FIELDS:\n",
    "                col_name_in_df = f\"game_{field_name}\"\n",
    "                if col_name_in_df in row_dict and pd.notna(row_dict[col_name_in_df]):\n",
    "                    value = row_dict[col_name_in_df]\n",
    "                    display_name = field_display_names.get(field_name, field_name)\n",
    "                    formatted_value = \"\"\n",
    "                    # (값 포맷팅 로직은 이전과 동일하게 적용)\n",
    "                    try:\n",
    "                        if field_name in ['minplayers', 'maxplayers', 'playingtime', 'minage']:\n",
    "                            formatted_value = f\"{int(float(value))}\"\n",
    "                            if field_name in ['minplayers', 'maxplayers']: formatted_value += \"명\"\n",
    "                            if field_name == 'playingtime': formatted_value += \"분\"\n",
    "                            if field_name == 'minage': formatted_value += \"세 이상\"\n",
    "                        elif field_name in ['averageweight', 'complexity', 'weight']:\n",
    "                            formatted_value = f\"{float(value):.2f}/5\"\n",
    "                        elif field_name == 'AvgRating':\n",
    "                            formatted_value = f\"{float(value):.2f}점\"\n",
    "                        elif field_name in ['Description', 'description_detail'] and len(str(value)) > 200:\n",
    "                             formatted_value = f\"{str(value)[:200]}...\" # 설명 길이는 조금 줄임\n",
    "                        elif isinstance(value, str) and value.strip().startswith('[') and value.strip().endswith(']'):\n",
    "                             try:\n",
    "                                 parsed_list = ast.literal_eval(value); formatted_value = \", \".join(map(str, parsed_list)) if isinstance(parsed_list, list) else str(value)\n",
    "                             except: formatted_value = value.strip(\"[]\").replace(\"'\", \"\").replace('\"', '')\n",
    "                        elif field_name != 'Game_Id': # Game_Id는 보통 내용에 포함 안 함\n",
    "                             formatted_value = str(value)\n",
    "\n",
    "                        # 내용 추가 (Title은 레이블 없이, 설명/ID 제외)\n",
    "                        if formatted_value and field_name not in ['Game_Id', 'Description', 'description_detail']:\n",
    "                            if field_name == 'Title': combined_parts.insert(0, f\"{display_name}: {formatted_value}\")\n",
    "                            else: combined_parts.append(f\"{display_name}: {formatted_value}\")\n",
    "\n",
    "                    except Exception: pass # 포맷팅 오류 시 해당 필드 건너뜀\n",
    "\n",
    "            # 설명 필드 추가\n",
    "            desc_text = \"\"\n",
    "            desc_col = next((c for c in [f'game_{f}' for f in ['Description', 'description', 'description_detail']] if c in row_dict and pd.notna(row_dict[c])), None)\n",
    "            if desc_col:\n",
    "                desc_val = str(row_dict[desc_col])\n",
    "                desc_text = f\"설명: {desc_val[:200]}...\" if len(desc_val) > 200 else f\"설명: {desc_val}\"\n",
    "\n",
    "            # 최종 page_content 결합\n",
    "            content_elements = [item for item in [ \"\\n\".join(combined_parts), desc_text, f\"리뷰: {review_text}\"] if item.strip()]\n",
    "            page_content = \"\\n\\n\".join(content_elements)\n",
    "\n",
    "        else: # enrich_text=False 이면 리뷰만 사용\n",
    "            page_content = review_text\n",
    "\n",
    "        # Document 객체 생성\n",
    "        if page_content:\n",
    "            return Document(page_content=page_content, metadata=metadata)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # 처리할 아이템 리스트\n",
    "    items_to_process = list(df.iterrows())\n",
    "    document_results = None\n",
    "\n",
    "    if parallel_mgr:\n",
    "         print(f\"\\n🔄 병렬 처리기로 Document 생성 시작 ({len(items_to_process):,}개 행)...\")\n",
    "         document_results = parallel_mgr.process_batch(\n",
    "             create_single_document,\n",
    "             items_to_process,\n",
    "             desc=\"Document 생성 (병렬)\"\n",
    "         )\n",
    "    else:\n",
    "         print(f\"\\n🔄 직렬 처리로 Document 생성 시작 ({len(items_to_process):,}개 행)...\")\n",
    "         document_results = []\n",
    "         for item in progress_bar(items_to_process, desc=\"Document 생성 (직렬)\"):\n",
    "             try:\n",
    "                  doc = create_single_document(item)\n",
    "                  if doc: document_results.append(doc)\n",
    "                  # else: # 리뷰 없거나 내용 생성 실패 시 건너뜀\n",
    "             except Exception as e:\n",
    "                  print(f\"⚠️ 행 처리 중 오류: {e}\")\n",
    "                  # 오류 발생 행은 건너뜀\n",
    "\n",
    "    # 결과 필터링 (None 제거)\n",
    "    final_documents = [doc for doc in document_results if doc is not None]\n",
    "    final_count = len(final_documents)\n",
    "\n",
    "    print(f\"\\n✅ Document 생성 완료: {final_count:,}개 생성됨\")\n",
    "\n",
    "    # --- 체크포인트 업데이트 ---\n",
    "    if checkpoint_mgr:\n",
    "        checkpoint_mgr.update_counter(\"documents_created\", final_count)\n",
    "        checkpoint_mgr.update_stage(stage_name, final_count > 0)\n",
    "        print(f\"✅ 체크포인트 업데이트: {stage_name}={'True' if final_count > 0 else 'False'}, count={final_count}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"⏱️ 총 처리 시간: {total_time:.2f}초\")\n",
    "    print(\"=\"*70)\n",
    "    return final_documents\n",
    "\n",
    "\n",
    "# split_documents (변경 없음 - 내부 로직은 유지)\n",
    "def split_documents(documents, max_chunk_size=MAX_CHUNK_SIZE, checkpoint_mgr=None, progress_bar=tqdm_notebook):\n",
    "    \"\"\"긴 문서를 적절한 크기로 분할\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✂️ 5단계: 문서 분할\")\n",
    "    print(\"=\"*70)\n",
    "    stage_name = \"documents_split\"\n",
    "\n",
    "    # --- 체크포인트 확인 ---\n",
    "    if checkpoint_mgr and checkpoint_mgr.is_stage_completed(stage_name):\n",
    "         split_count = checkpoint_mgr.state[\"counters\"][\"documents_split\"]\n",
    "         print(f\"✅ 문서 분할 단계는 이전에 완료되었습니다 (분할된 문서: {split_count:,}).\")\n",
    "         # 여기서 건너뛰려면 이전 결과 로드 필요. 일단 진행.\n",
    "         print(\"   (체크포인트 확인. 문서 분할을 다시 진행합니다)\")\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if not documents:\n",
    "        print(\"❌ 분할할 문서가 없습니다.\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return []\n",
    "\n",
    "    # (문서 길이 통계 계산 로직 유지)\n",
    "    doc_lengths = [len(doc.page_content) for doc in documents if hasattr(doc, 'page_content')]\n",
    "    if not doc_lengths: print(\"❌ 유효한 문서 내용이 없어 분할 불가.\"); return documents\n",
    "    max_len = max(doc_lengths)\n",
    "    print(f\"   - 최대 문서 길이: {max_len:,}자\")\n",
    "\n",
    "    if max_len <= max_chunk_size:\n",
    "        print(f\"✅ 모든 문서가 청크 크기({max_chunk_size}) 이하이므로 분할 건너뜁니다.\")\n",
    "        if checkpoint_mgr:\n",
    "             # 분할이 필요 없었으므로 완료로 간주, 카운트는 원본 문서 수\n",
    "             checkpoint_mgr.update_counter(\"documents_split\", len(documents))\n",
    "             checkpoint_mgr.update_stage(stage_name, True)\n",
    "        return documents\n",
    "\n",
    "    print(f\"\\n🔪 문서를 {max_chunk_size}자 단위로 분할 중...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_chunk_size,\n",
    "        chunk_overlap=int(max_chunk_size * 0.1),\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \", \", \" \", \"\"],\n",
    "        keep_separator=False\n",
    "    )\n",
    "\n",
    "    split_docs = []\n",
    "    split_errors = 0\n",
    "    # 분할은 병렬화 효과가 크지 않을 수 있음 (LangChain 내부 최적화 가능성)\n",
    "    # 여기서는 직렬 처리 유지, 필요 시 병렬화 고려\n",
    "    try:\n",
    "        split_docs = text_splitter.split_documents(documents)\n",
    "    except Exception as e:\n",
    "         print(f\"❌ 문서 분할 중 오류 발생: {e}\")\n",
    "         split_errors += 1\n",
    "         # 오류 시 원본 반환 또는 빈 리스트 반환 결정 필요\n",
    "         if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "         return documents # 오류 시 원본 반환\n",
    "\n",
    "    final_count = len(split_docs)\n",
    "    print(f\"\\n📊 분할 결과: {len(documents):,}개 -> {final_count:,}개 문서\")\n",
    "    if split_errors > 0: print(f\"   ⚠️ 분할 중 오류 발생 건수: {split_errors:,}\")\n",
    "\n",
    "    # --- 체크포인트 업데이트 ---\n",
    "    if checkpoint_mgr:\n",
    "        checkpoint_mgr.update_counter(\"documents_split\", final_count)\n",
    "        checkpoint_mgr.update_stage(stage_name, final_count > 0)\n",
    "        print(f\"✅ 체크포인트 업데이트: {stage_name}={'True' if final_count > 0 else 'False'}, count={final_count}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"⏱️ 총 처리 시간: {total_time:.2f}초\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "\n",
    "# setup_vectorstore (변경 없음 - 내부 로직은 유지)\n",
    "def setup_vectorstore(model_name=MODEL_NAME, persist_dir=CHROMA_PERSIST_DIR, device=\"cpu\", checkpoint_mgr=None):\n",
    "    \"\"\"임베딩 모델 로드 및 벡터 저장소 설정 또는 로드\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🏗️ 6단계: 벡터 저장소 설정/로드\")\n",
    "    print(\"=\"*70)\n",
    "    stage_name = \"vectorstore_setup\" # setup 단계 자체는 상태 저장이 덜 중요할 수 있음\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"   - 모델: {model_name}\")\n",
    "    print(f\"   - 저장 경로: {persist_dir}\")\n",
    "    print(f\"   - 사용 장치: {device}\")\n",
    "\n",
    "    # 1. 임베딩 모델 로드\n",
    "    embeddings = None\n",
    "    try:\n",
    "        print(\"\\n🧠 임베딩 모델 로드 중...\")\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs={'device': device},\n",
    "            encode_kwargs={'normalize_embeddings': True, 'batch_size': 128} # 적절한 배치 크기\n",
    "        )\n",
    "        print(f\"✅ 임베딩 모델 로드 완료 ({model_name})\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 임베딩 모델 로드 오류: {e}\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return None # 모델 로드 실패 시 진행 불가\n",
    "\n",
    "    # 2. ChromaDB 설정 또는 로드\n",
    "    vectorstore = None\n",
    "    try:\n",
    "        print(\"\\n💾 ChromaDB 설정/로드 중...\")\n",
    "        if os.path.exists(persist_dir) and os.listdir(persist_dir):\n",
    "            print(f\"   ℹ️ 기존 DB 발견: {persist_dir}. 로드 시도...\")\n",
    "            vectorstore = Chroma(\n",
    "                persist_directory=persist_dir,\n",
    "                embedding_function=embeddings\n",
    "            )\n",
    "            print(f\"   ✅ 기존 ChromaDB 로드 완료.\")\n",
    "            try:\n",
    "                 count = vectorstore._collection.count()\n",
    "                 print(f\"   📊 로드된 DB 문서 수: {count:,}\")\n",
    "            except Exception as e_count:\n",
    "                 print(f\"   ⚠️ 로드된 DB 문서 수 확인 오류: {e_count}\")\n",
    "        else:\n",
    "            print(f\"   ℹ️ 새 ChromaDB 생성: {persist_dir}\")\n",
    "            os.makedirs(persist_dir, exist_ok=True)\n",
    "            # 문서는 add_documents 단계에서 추가하므로 여기서는 빈 DB 생성\n",
    "            vectorstore = Chroma(\n",
    "                persist_directory=persist_dir,\n",
    "                embedding_function=embeddings\n",
    "            )\n",
    "            print(f\"   ✅ 새 ChromaDB 인스턴스 준비 완료.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ChromaDB 설정/로드 오류: {e}\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return None\n",
    "\n",
    "    # --- 체크포인트 업데이트 ---\n",
    "    # setup 단계는 성공/실패 여부만 기록해도 충분할 수 있음\n",
    "    if checkpoint_mgr:\n",
    "         checkpoint_mgr.update_stage(stage_name, vectorstore is not None)\n",
    "         print(f\"✅ 체크포인트 업데이트: {stage_name}={'True' if vectorstore else 'False'}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n⏱️ 총 처리 시간: {total_time:.2f}초\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# add_documents_to_vectorstore (체크포인트 ID 확인 및 배치 재개 로직 추가)\n",
    "def add_documents_to_vectorstore(documents, vectorstore, batch_size=BATCH_SIZE, checkpoint_mgr=None, progress_bar=tqdm_notebook):\n",
    "    \"\"\"문서를 벡터 저장소에 추가 (배치 처리, ID 중복 방지, 체크포인트 재개)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"📥 7단계: 벡터 저장소에 문서 추가\")\n",
    "    print(\"=\"*70)\n",
    "    stage_name = \"documents_added\" # 이 단계의 완료 여부가 중요\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if not documents:\n",
    "        print(\"✅ 추가할 새 문서가 없습니다.\")\n",
    "        # 문서가 없어도 단계는 '완료'로 볼 수 있음 (할 일이 없으므로)\n",
    "        if checkpoint_mgr and not checkpoint_mgr.is_stage_completed(stage_name):\n",
    "              checkpoint_mgr.update_stage(stage_name, True)\n",
    "              print(\"   (체크포인트 업데이트: 추가할 문서 없음, 완료로 간주)\")\n",
    "        return vectorstore\n",
    "\n",
    "    if not vectorstore:\n",
    "        print(\"❌ 벡터 저장소가 설정되지 않아 문서 추가 불가.\")\n",
    "        if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, False)\n",
    "        return None\n",
    "\n",
    "    total_docs_to_process = len(documents)\n",
    "    print(f\"   - 추가 시도 문서 수: {total_docs_to_process:,}\")\n",
    "    print(f\"   - 배치 크기: {batch_size}\")\n",
    "\n",
    "    # --- 체크포인트 기반 재개 로직 ---\n",
    "    start_index = 0\n",
    "    previously_added_ids = set()\n",
    "    if checkpoint_mgr:\n",
    "        # 이전에 마지막으로 성공한 배치 인덱스 확인\n",
    "        last_added_batch_idx = checkpoint_mgr.state[\"counters\"].get(\"last_added_batch_index\", -1)\n",
    "        if last_added_batch_idx >= 0:\n",
    "             start_index = (last_added_batch_idx + 1) * batch_size\n",
    "             print(f\"🔄 체크포인트 발견: 마지막 성공 배치 인덱스 {last_added_batch_idx}.\")\n",
    "             if start_index >= total_docs_to_process:\n",
    "                 print(\"   ✅ 모든 문서가 이미 이전 실행에서 추가된 것으로 보입니다.\")\n",
    "                 if not checkpoint_mgr.is_stage_completed(stage_name):\n",
    "                      checkpoint_mgr.update_stage(stage_name, True) # 완료 상태 업데이트\n",
    "                 return vectorstore\n",
    "             else:\n",
    "                  print(f\"   -> 인덱스 {start_index}부터 문서 추가를 재개합니다.\")\n",
    "\n",
    "        # 이미 추가된 문서 ID 로드 (중복 추가 방지용)\n",
    "        previously_added_ids = checkpoint_mgr.state[\"processed_ids\"].get(\"document_ids\", set())\n",
    "        if previously_added_ids:\n",
    "             print(f\"   ℹ️ 체크포인트에서 로드된 이전 추가 문서 ID: {len(previously_added_ids):,}개 (중복 방지용)\")\n",
    "\n",
    "\n",
    "    # 문서 ID 생성 및 필터링 (재개 인덱스 및 중복 ID 고려)\n",
    "    docs_to_add_this_run = []\n",
    "    ids_to_add_this_run = []\n",
    "    processed_for_id_gen = 0\n",
    "    skipped_already_added = 0\n",
    "    unique_generated_ids = set(previously_added_ids) # 기존 ID 포함하여 시작\n",
    "\n",
    "    # ID 생성기 (충돌 방지 포함)\n",
    "    import hashlib\n",
    "    import uuid\n",
    "    def generate_unique_doc_id(doc, idx, existing_ids):\n",
    "        content_hash = hashlib.md5(doc.page_content.encode()).hexdigest()[:8]\n",
    "        base_id = f\"doc_{idx}_{content_hash}\" # 인덱스와 내용 해시 기반\n",
    "        # 메타데이터에서 식별자 사용 시도 (선택적)\n",
    "        # meta_id = doc.metadata.get('game_Game_Id', doc.metadata.get('id'))\n",
    "        # if meta_id: base_id = f\"{meta_id}_{content_hash}\"\n",
    "\n",
    "        final_id = base_id\n",
    "        counter = 0\n",
    "        while final_id in existing_ids:\n",
    "            counter += 1\n",
    "            final_id = f\"{base_id}_dup{counter}\"\n",
    "        return final_id\n",
    "\n",
    "    print(\"   ID 생성 및 중복 확인 중...\")\n",
    "    # 재개 지점부터 ID 생성 및 필터링\n",
    "    for idx, doc in enumerate(documents[start_index:], start=start_index):\n",
    "        processed_for_id_gen += 1\n",
    "        generated_id = generate_unique_doc_id(doc, idx, unique_generated_ids)\n",
    "\n",
    "        # previously_added_ids 에 있으면 건너뛰기 (이미 DB에 있을 가능성 높음)\n",
    "        if generated_id in previously_added_ids:\n",
    "            skipped_already_added += 1\n",
    "            continue\n",
    "\n",
    "        docs_to_add_this_run.append(doc)\n",
    "        ids_to_add_this_run.append(generated_id)\n",
    "        unique_generated_ids.add(generated_id) # 새로 생성된 ID도 집합에 추가\n",
    "\n",
    "    print(f\"   ID 생성 완료: {processed_for_id_gen}개 확인, {skipped_already_added}개 건너뜀.\")\n",
    "    print(f\"   이번 실행에서 DB에 추가할 문서 수: {len(docs_to_add_this_run):,}\")\n",
    "\n",
    "    if not docs_to_add_this_run:\n",
    "        print(\"✅ 이번 실행에서 추가할 새 문서가 없습니다.\")\n",
    "        if checkpoint_mgr and not checkpoint_mgr.is_stage_completed(stage_name):\n",
    "             checkpoint_mgr.update_stage(stage_name, True) # 추가할 것 없으면 완료\n",
    "        return vectorstore\n",
    "\n",
    "    # 배치 처리\n",
    "    total_batches = (len(docs_to_add_this_run) + batch_size - 1) // batch_size\n",
    "    added_count_this_run = 0\n",
    "    current_batch_index_global = (start_index // batch_size) # 전역 배치 인덱스 (체크포인트용)\n",
    "\n",
    "    print(f\"\\n🔄 {total_batches}개 배치로 나누어 문서 추가 시작 (전역 배치 인덱스 {current_batch_index_global}부터)...\")\n",
    "\n",
    "    # DB 추가 전 현재 문서 수 확인\n",
    "    try: initial_db_count = vectorstore._collection.count()\n",
    "    except: initial_db_count = -1 # 확인 불가 시\n",
    "\n",
    "    # 배치 루프\n",
    "    for i in range(0, len(docs_to_add_this_run), batch_size):\n",
    "        batch_docs = docs_to_add_this_run[i : i + batch_size]\n",
    "        batch_ids = ids_to_add_this_run[i : i + batch_size]\n",
    "        current_batch_index_local = i // batch_size # 이번 실행 내 배치 인덱스\n",
    "        current_batch_index_global = (start_index + i) // batch_size # 전역 배치 인덱스\n",
    "\n",
    "        progress_desc = f\"벡터 저장소 추가 (배치 {current_batch_index_local+1}/{total_batches}, 전역 {current_batch_index_global})\"\n",
    "\n",
    "        try:\n",
    "             # tqdm 적용하여 add_documents 호출\n",
    "             # 참고: add_documents 자체가 오래 걸릴 수 있으므로, tqdm이 즉각 반응 안 할 수 있음\n",
    "             #       하지만 배치 단위로는 표시됨\n",
    "             vectorstore.add_documents(documents=batch_docs, ids=batch_ids)\n",
    "             added_count_this_run += len(batch_docs)\n",
    "\n",
    "             # --- 체크포인트 업데이트 (배치 성공 시) ---\n",
    "             if checkpoint_mgr:\n",
    "                 # 성공한 전역 배치 인덱스 저장\n",
    "                 checkpoint_mgr.update_counter(\"last_added_batch_index\", current_batch_index_global)\n",
    "                 # 성공적으로 추가된 ID 저장 (메모리 사용량 주의하며 주기적으로 저장)\n",
    "                 checkpoint_mgr.add_processed_ids(\"document_ids\", batch_ids)\n",
    "                 # 누적 추가 카운터 업데이트 (선택적)\n",
    "                 # checkpoint_mgr.update_counter(\"documents_added\", checkpoint_mgr.state[\"counters\"][\"documents_added\"] + len(batch_docs))\n",
    "\n",
    "             # 진행률 표시 (tqdm과 별개로)\n",
    "             if (current_batch_index_local + 1) % 10 == 0: # 10 배치마다 로그 출력\n",
    "                  print(f\"   진행: {current_batch_index_local + 1}/{total_batches} 배치 완료 ({added_count_this_run:,}개 문서 추가됨)\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 배치 {current_batch_index_local + 1} (전역 {current_batch_index_global}) 처리 중 오류: {e}\")\n",
    "            # 오류 발생 시 해당 배치 건너뛰고 다음 배치 진행\n",
    "            # 또는 파이프라인 중단 결정\n",
    "            print(\"   ⚠️ 해당 배치 건너뛰고 계속 진행합니다.\")\n",
    "            # 오류 발생 시 체크포인트 업데이트는 하지 않음\n",
    "            continue # 다음 배치로\n",
    "\n",
    "\n",
    "    print(f\"\\n✅ 문서 추가 작업 완료 (이번 실행에서 {added_count_this_run:,}개 시도).\")\n",
    "\n",
    "    # 최종 저장 (persist)\n",
    "    try:\n",
    "        print(\"\\n💾 변경사항 저장 중...\")\n",
    "        vectorstore.persist()\n",
    "        print(\"✅ 저장 완료.\")\n",
    "    except Exception as e_persist:\n",
    "        print(f\"   ⚠️ 저장 중 오류: {e_persist}\")\n",
    "\n",
    "    # 최종 문서 수 확인\n",
    "    try:\n",
    "        final_db_count = vectorstore._collection.count()\n",
    "        print(f\"\\n📊 최종 DB 문서 수 (확인): {final_db_count:,}\")\n",
    "        if initial_db_count != -1:\n",
    "            net_added = final_db_count - initial_db_count\n",
    "            print(f\"   - 순 증가 문서 수: {net_added:,}\")\n",
    "    except Exception as e:\n",
    "        print(\"\\n⚠️ 최종 문서 수 확인 중 오류: {e}\")\n",
    "\n",
    "\n",
    "    # --- 최종 체크포인트 업데이트 ---\n",
    "    if checkpoint_mgr:\n",
    "        final_added_count = checkpoint_mgr.get_processed_ids_count(\"document_ids\")\n",
    "        checkpoint_mgr.update_counter(\"documents_added\", final_added_count) # 전체 누적 ID 수로 업데이트\n",
    "\n",
    "        # 모든 문서가 처리되었는지 확인 후 완료 상태 업데이트\n",
    "        # (start_index + len(docs_to_add_this_run)) 이 원래 문서 수와 같으면 완료\n",
    "        is_complete = (start_index + len(docs_to_add_this_run)) >= total_docs_to_process\n",
    "        if is_complete:\n",
    "             checkpoint_mgr.update_stage(stage_name, True)\n",
    "             print(f\"✅ 체크포인트 업데이트: {stage_name}=True (모든 문서 처리 완료)\")\n",
    "        else:\n",
    "             # 아직 처리할 문서가 남음 (오류 등으로 중단된 경우)\n",
    "             checkpoint_mgr.update_stage(stage_name, False)\n",
    "             print(f\"⚠️ 체크포인트 업데이트: {stage_name}=False (아직 처리할 문서 남음)\")\n",
    "\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n⏱️ 총 처리 시간: {total_time:.2f}초\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# test_vectorstore (변경 없음 - 내부 로직은 유지)\n",
    "def test_vectorstore(vectorstore, checkpoint_mgr=None):\n",
    "    \"\"\"벡터 저장소 테스트 (E5 쿼리 포맷팅 적용)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70); print(\"🧪 8단계: 벡터 저장소 테스트\"); print(\"=\"*70)\n",
    "    stage_name=\"vectorstore_tested\"\n",
    "\n",
    "    if vectorstore is None: print(\"❌ 저장소 없음.\"); return None\n",
    "\n",
    "    try: doc_count = vectorstore._collection.count(); print(f\"📊 문서 수: {doc_count:,}\")\n",
    "    except: doc_count = 0; print(\"⚠️ 문서 수 확인 불가\")\n",
    "    if doc_count == 0: print(\"   ⚠️ 문서 없음.\"); return vectorstore\n",
    "\n",
    "    test_queries = [ \"아이들과 함께하는 게임\", \"전략적인 게임 추천\", \"짧은 플레이 타임의 게임\", \"Catan\" ]\n",
    "    print(\"\\n🔍 기본 쿼리 테스트 (상위 3개 결과):\")\n",
    "\n",
    "    # --- <<< E5 모델 확인 및 쿼리 포맷팅 적용 >>> ---\n",
    "    is_e5_model = MODEL_NAME.startswith(\"intfloat/e5\") or MODEL_NAME.startswith(\"intfloat/multilingual-e5\")\n",
    "    if is_e5_model:\n",
    "        print(\"   ℹ️ E5 모델 감지: 검색 쿼리에 'query: ' 접두사 적용\")\n",
    "\n",
    "    for query in test_queries:\n",
    "        # --- <<< 쿼리 포맷팅 적용 >>> ---\n",
    "        search_query = format_query(query) if is_e5_model else query\n",
    "        print(f\"\\n📝 쿼리: '{query}' {'(포맷팅 적용됨)' if is_e5_model else ''}\")\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            results = vectorstore.similarity_search_with_score(search_query, k=3) # 포맷팅된 쿼리 사용\n",
    "            search_time = time.time() - start_time\n",
    "            print(f\"⏱️ 검색 시간: {search_time*1000:.2f}ms\")\n",
    "            if results:\n",
    "                print(f\"📄 검색 결과 ({len(results)}개):\")\n",
    "                for i, (doc, score) in enumerate(results):\n",
    "                    title = doc.metadata.get('game_Title', doc.metadata.get('Title', '?'))\n",
    "                    game_id = doc.metadata.get('game_Game_Id', doc.metadata.get('Game_Id', '?'))\n",
    "                    # --- <<< Passage 접두사 제거 후 출력 (선택적) >>> ---\n",
    "                    content_preview = doc.page_content\n",
    "                    if content_preview.startswith(\"passage: \"):\n",
    "                         content_preview = content_preview[len(\"passage: \"):]\n",
    "                    content_preview = content_preview.replace('\\n', ' ').strip()\n",
    "                    print(f\"  Rank {i+1} (Score: {score:.4f}) ID:{game_id} Title:{title}\")\n",
    "                    print(f\"    내용: {content_preview[:150]}...\")\n",
    "            else: print(\"  ❌ 결과 없음\")\n",
    "        except Exception as e: print(f\"❌ 쿼리 오류: {e}\")\n",
    "\n",
    "    if checkpoint_mgr: checkpoint_mgr.update_stage(stage_name, True)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# --- [수정된 run_pipeline 함수] ---\n",
    "def run_pipeline(\n",
    "    resume=False,\n",
    "    reset_checkpoint=False,\n",
    "    use_parallel=True, # 병렬 처리 사용 여부 플래그\n",
    "    parallel_use_processes=False # 병렬 처리 방식 (False: 스레드, True: 프로세스)\n",
    "):\n",
    "    \"\"\"전체 파이프라인 실행 (체크포인트, 병렬 처리 적용)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🚀 보드게임 추천 시스템 파이프라인 시작 (개선 버전)\")\n",
    "    print(f\"⏱️ 시작 시간: {time.strftime('%H:%M:%S')}\")\n",
    "    print(f\"🔄 옵션: resume={resume}, reset_checkpoint={reset_checkpoint}, use_parallel={use_parallel}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    pipeline_start = time.time()\n",
    "    vectorstore = None\n",
    "\n",
    "    # 0. 초기 설정 및 진단\n",
    "    print(\"\\n📋 0단계: 초기 설정 및 진단\")\n",
    "    has_gpu = check_gpu_status()\n",
    "    device = \"cuda\" if has_gpu else \"cpu\"\n",
    "    print(f\"🖥️ 사용 장치: {device}\")\n",
    "    progress_bar = setup_progress_bar() # 환경에 맞는 tqdm 가져오기\n",
    "\n",
    "    # 체크포인트 관리자 초기화\n",
    "    checkpoint_mgr = CheckpointManager(\"boardgame_pipeline_integrated_e5\")\n",
    "\n",
    "    # 리셋 옵션 처리\n",
    "    if reset_checkpoint:\n",
    "        print(\"🔄 체크포인트 초기화 요청됨...\")\n",
    "        checkpoint_mgr.reset()\n",
    "        resume = False # 리셋하면 재개할 수 없음\n",
    "\n",
    "    # 재개 모드 처리\n",
    "    if resume:\n",
    "        resume_info = checkpoint_mgr.get_resume_info()\n",
    "        if resume_info[\"can_resume\"]:\n",
    "            print(\"\\n🔄 이전 세션에서 파이프라인 재개:\")\n",
    "            print(f\"   마지막 업데이트: {resume_info['last_update']}\")\n",
    "            print(f\"   완료된 단계: {', '.join(resume_info['completed_stages'])}\")\n",
    "            # 카운터 정보 출력 등...\n",
    "        else:\n",
    "            print(\"⚠️ 재개할 수 있는 이전 세션 없음. 처음부터 시작.\")\n",
    "            resume = False # 재개 불가능하면 처음부터\n",
    "\n",
    "    # 병렬 처리 관리자 초기화\n",
    "    parallel_mgr = ParallelProcessor(use_processes=parallel_use_processes) if use_parallel else None\n",
    "\n",
    "\n",
    "    # --- 파이프라인 단계 실행 ---\n",
    "    try:\n",
    "        # 1. 메타데이터 로드\n",
    "        # 메타데이터는 보통 변경이 잦지 않으므로, 체크포인트 완료 시 건너뛰지 않고\n",
    "        # 함수 내부에서 파일 경로 비교 등을 통해 재로드를 결정할 수 있음.\n",
    "        # 여기서는 항상 호출하되, 내부 로직이 체크포인트 정보를 활용하도록 함.\n",
    "        metadata_dict, meta_id_column = load_game_metadata(\n",
    "            METADATA_CSV_PATH,\n",
    "            checkpoint_mgr,\n",
    "            progress_bar\n",
    "        )\n",
    "        if metadata_dict is None:\n",
    "             print(\"❌ 1단계: 메타데이터 로드 실패. 파이프라인 중단.\")\n",
    "             return None\n",
    "\n",
    "        # 2. 리뷰 데이터 처리\n",
    "        review_df, review_column, review_id_column = preprocess_reviews(\n",
    "            REVIEW_CSV_PATH,\n",
    "            checkpoint_mgr,\n",
    "            progress_bar\n",
    "        )\n",
    "        # preprocess_reviews 내부에서 체크포인트를 사용하여 이미 처리된 ID 건너뜀\n",
    "        if review_df is None or review_column is None:\n",
    "             print(\"❌ 2단계: 리뷰 데이터 처리 실패. 파이프라인 중단.\")\n",
    "             return None\n",
    "\n",
    "        # 3. 데이터 통합 (Enrichment)\n",
    "        enriched_df = enrich_review_data_fixed(\n",
    "            review_df, metadata_dict, meta_id_column, review_id_column,\n",
    "            parallel_mgr, # 병렬 관리자 전달\n",
    "            checkpoint_mgr,\n",
    "            progress_bar\n",
    "        )\n",
    "        if enriched_df is None or enriched_df.empty:\n",
    "             print(\"❌ 3단계: 데이터 통합 후 유효 데이터 없음. 파이프라인 중단.\")\n",
    "             return None\n",
    "\n",
    "        # 4. Document 객체 생성\n",
    "        documents = create_documents(\n",
    "            enriched_df, review_column, ENRICH_TEXT,\n",
    "            parallel_mgr, # 병렬 관리자 전달\n",
    "            checkpoint_mgr,\n",
    "            progress_bar\n",
    "        )\n",
    "        if not documents:\n",
    "             print(\"❌ 4단계: Document 객체 생성 실패. 파이프라인 중단.\")\n",
    "             return None\n",
    "\n",
    "        # 5. 문서 분할\n",
    "        split_docs = split_documents(\n",
    "            documents, MAX_CHUNK_SIZE,\n",
    "            checkpoint_mgr,\n",
    "            progress_bar\n",
    "        )\n",
    "        # split_documents 내부에서 체크포인트 확인 및 상태 업데이트\n",
    "\n",
    "        # 6. 벡터 저장소 설정/로드\n",
    "        vectorstore = setup_vectorstore(\n",
    "            MODEL_NAME, CHROMA_PERSIST_DIR, device,\n",
    "            checkpoint_mgr\n",
    "        )\n",
    "        if vectorstore is None:\n",
    "             print(\"❌ 6단계: 벡터 저장소 설정/로드 실패. 파이프라인 중단.\")\n",
    "             return None\n",
    "         # --- <<< NEW: E5 모델 Passage 포맷팅 적용 단계 >>> ---\n",
    "        formatted_docs_for_db = split_docs # 기본값은 원본 사용\n",
    "        formatting_stage_name = \"passage_formatting_applied\"\n",
    "        is_e5_model = MODEL_NAME.startswith(\"intfloat/e5\") or MODEL_NAME.startswith(\"intfloat/multilingual-e5\")\n",
    "\n",
    "        if is_e5_model:\n",
    "            print(\"\\n\" + \"=\"*70); print(\"📜 6.5단계: E5 Passage 포맷팅 적용\"); print(\"=\"*70)\n",
    "            reload_formatting = True\n",
    "            if checkpoint_mgr and checkpoint_mgr.is_stage_completed(formatting_stage_name):\n",
    "                 print(\"✅ Passage 포맷팅은 이전 완료됨 (체크포인트)\")\n",
    "                 # reload_formatting = False # 건너뛰기 옵션\n",
    "\n",
    "            if reload_formatting:\n",
    "                st_format = time.time()\n",
    "                formatted_docs_list = []\n",
    "                for doc in progress_bar(split_docs, desc=\"Passage 포맷팅\"):\n",
    "                     formatted_content = format_passage(doc.page_content)\n",
    "                     # 메타데이터 유지하며 새 Document 생성\n",
    "                     formatted_docs_list.append(Document(page_content=formatted_content, metadata=doc.metadata))\n",
    "                formatted_docs_for_db = formatted_docs_list\n",
    "                print(f\"✅ 포맷팅 완료: {len(formatted_docs_for_db):,}개 문서 ({time.time()-st_format:.2f}초)\")\n",
    "                if checkpoint_mgr:\n",
    "                    checkpoint_mgr.update_stage(formatting_stage_name, True)\n",
    "                    print(f\"✅ 체크포인트 업데이트: {formatting_stage_name}=True\")\n",
    "            else:\n",
    "                 # 포맷팅 건너뛸 경우, 이전에 포맷팅된 데이터를 로드해야 함.\n",
    "                 # 로드 로직 없으므로 일단 원본 사용 (경고 표시)\n",
    "                 print(\"   ⚠️ 포맷팅 건너뛰기 선택됨 (데이터 로드 로직 부재로 원본 사용)\")\n",
    "                 formatted_docs_for_db = split_docs\n",
    "        else:\n",
    "             print(\"\\nℹ️ E5 모델 아님. Passage 포맷팅 건너뜀.\")\n",
    "        # --- <<< End of E5 Formatting Section >>> ---\n",
    "\n",
    "        # 7. 벡터 저장소에 문서 추가\n",
    "        # add_documents_to_vectorstore 내부에서 체크포인트 기반 재개 및 중복 방지 처리\n",
    "        vectorstore = add_documents_to_vectorstore(\n",
    "            split_docs, vectorstore, BATCH_SIZE,\n",
    "            checkpoint_mgr,\n",
    "            progress_bar\n",
    "        )\n",
    "        if vectorstore is None:\n",
    "             print(\"❌ 7단계: 문서 추가 중 오류 발생. 파이프라인 중단.\")\n",
    "             return None\n",
    "\n",
    "        # 8. 벡터 저장소 테스트\n",
    "        vectorstore = test_vectorstore(vectorstore, checkpoint_mgr)\n",
    "\n",
    "\n",
    "        # --- 파이프라인 완료 ---\n",
    "        pipeline_time = time.time() - pipeline_start\n",
    "        minutes, seconds = divmod(pipeline_time, 60)\n",
    "        hours, minutes = divmod(minutes, 60)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"✅ 보드게임 추천 시스템 파이프라인 완료 (개선 버전)\")\n",
    "        print(f\"⏱️ 총 처리 시간: {int(hours)}시간 {int(minutes)}분 {seconds:.2f}초\")\n",
    "        print(f\"⏱️ 완료 시간: {time.strftime('%H:%M:%S')}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # 최종 요약 정보 (체크포인트 정보 활용)\n",
    "        print(\"\\n📊 파이프라인 요약 (체크포인트 기준):\")\n",
    "        try:\n",
    "             final_state = checkpoint_mgr.get_resume_info()\n",
    "             counters = final_state[\"counters\"]\n",
    "             processed_counts = final_state[\"processed_counts\"]\n",
    "             db_count = vectorstore._collection.count() if vectorstore else 0\n",
    "\n",
    "             print(f\"   - 로드된 메타데이터 (카운터): {counters.get('metadata_count', 0):,}\")\n",
    "             print(f\"   - 처리된 리뷰 (카운터): {counters.get('reviews_processed', 0):,}\")\n",
    "             print(f\"   - 통합된 행 (카운터): {counters.get('enriched_count', 0):,}\")\n",
    "             print(f\"   - 생성된 Document (카운터): {counters.get('documents_created', 0):,}\")\n",
    "             print(f\"   - 분할된 문서 (카운터): {counters.get('documents_split', 0):,}\")\n",
    "             print(f\"   - DB에 추가된 문서 ID (누적): {processed_counts.get('documents', 0):,}\")\n",
    "             print(f\"   - 최종 벡터 저장소 문서 수 (실제): {db_count:,}\")\n",
    "             print(f\"   - 최종 벡터 저장소 위치: {CHROMA_PERSIST_DIR}\")\n",
    "        except Exception as e_summary:\n",
    "             print(f\"   ⚠️ 요약 정보 생성 중 오류: {e_summary}\")\n",
    "\n",
    "        return vectorstore\n",
    "\n",
    "    # --- 예외 처리 ---\n",
    "    except FileNotFoundError as fnf_error:\n",
    "         print(f\"\\n❌ 파이프라인 오류: 파일 없음 - {fnf_error}\")\n",
    "         return None\n",
    "    except ValueError as val_error:\n",
    "         print(f\"\\n❌ 파이프라인 오류: 데이터 문제 - {val_error}\")\n",
    "         return None\n",
    "    except ImportError as imp_error:\n",
    "         print(f\"\\n❌ 파이프라인 오류: 라이브러리 없음 - {imp_error}\")\n",
    "         return None\n",
    "    except KeyboardInterrupt:\n",
    "         print(\"\\n🚫 사용자에 의해 파이프라인 중단됨.\")\n",
    "         # 중단 시 현재 상태 저장 시도 (선택적)\n",
    "         if checkpoint_mgr:\n",
    "              print(\"   현재까지의 진행 상황을 체크포인트에 저장합니다...\")\n",
    "              checkpoint_mgr.save()\n",
    "         return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 파이프라인 실행 중 예기치 않은 오류: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # 오류 발생 시 현재 상태 저장 시도 (선택적)\n",
    "        if checkpoint_mgr:\n",
    "             print(\"   오류 발생 전까지의 상태를 체크포인트에 저장 시도...\")\n",
    "             checkpoint_mgr.save()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"⚠️ 보드게임 추천 시스템 파이프라인 실패\")\n",
    "        print(f\"⏱️ 중단 시간: {time.strftime('%H:%M:%S')}\")\n",
    "        print(\"=\"*70)\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 파이프라인 실행 ---\n",
    "if __name__ == \"__main__\": # 스크립트로 실행될 때만 실행\n",
    "    print(\"--- 파이프라인 실행 시작 ---\")\n",
    "\n",
    "    # 실행 옵션 설정\n",
    "    # 예시: 처음 실행 시\n",
    "    # final_vectorstore = run_pipeline(resume=False, reset_checkpoint=False, use_parallel=True)\n",
    "\n",
    "    # 예시: 중단 후 재개 시\n",
    "    final_vectorstore = run_pipeline(resume=True, reset_checkpoint=False, use_parallel=True, parallel_use_processes=False)\n",
    "\n",
    "    # 예시: 처음부터 다시 실행 (체크포인트 무시)\n",
    "    # final_vectorstore = run_pipeline(resume=False, reset_checkpoint=True, use_parallel=True)\n",
    "\n",
    "    if final_vectorstore:\n",
    "        print(\"\\n--- 파이프라인 성공적으로 완료. final_vectorstore 사용 가능 ---\")\n",
    "        # 간단한 추가 테스트\n",
    "        # try:\n",
    "        #     test_query = \"협력 게임\"\n",
    "        #     results = final_vectorstore.similarity_search(test_query, k=5)\n",
    "        #     print(f\"\\n테스트 검색 ('{test_query}'):\")`\n",
    "        #     for doc in results:\n",
    "        #         print(f\" - {doc.metadata.get('game_Title', '제목 없음')}\")\n",
    "        # except Exception as e:\n",
    "        #      print(f\"최종 검색 테스트 중 오류: {e}\")\n",
    "    else:\n",
    "        print(\"\\n--- 파이프라인 실패 또는 중단 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91a76e-a44a-4e96-b8e4-c50625531b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cd0e1-00db-40ee-bbac-84e0981f5339",
   "metadata": {},
   "source": [
    "## 5. 메타데이터와 리뷰 데이터 통합 (최적화 버전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b0bbb-d779-4d89-9541-6f7fb3e34826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e5f58-83fa-4e03-b4cf-357501667110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481b086-0cee-4850-aa15-d59b82f13f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d66565-16f1-4417-983e-db65f7bc671b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3734aa-bddb-453a-8065-2cc0fbc53d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae586deb-429c-41b2-8a8b-6aa15f0c5a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}